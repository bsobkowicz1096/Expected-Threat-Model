{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3956b3b3-ef2e-43ff-b187-38c4ed6d16ee",
   "metadata": {},
   "source": [
    "## Implementacja\n",
    "\n",
    "Implementacja modelu Expected Threat wykorzystującego:\n",
    "- **Transformer encoder** (12 warstw, 512 d_model) do przetwarzania sekwencji zdarzeń\n",
    "- **Mixture Density Network (MDN)** z 5 komponentami Gaussowskimi do predykcji pozycji\n",
    "- **Fourier position encoding** dla płynnej reprezentacji współrzędnych na boisku\n",
    "- **Autoregresywna predykcja** z causal masking - każdy event przewiduje następny\n",
    "\n",
    "Podejście eliminuje dyskretyzację siatki i pozwala modelowi przewidywać realistyczne, ciągłe rozkłady pozycji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7184e56d-729d-46cb-9669-3dc8325117b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F \n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49048c80-a364-4737-b7e1-da2f4ccf2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAIN SET\n",
      "============================================================\n",
      "Sequences: 73,436\n",
      "Goals: 3,736 (5.1%)\n",
      "\n",
      "============================================================\n",
      "VALIDATION SET\n",
      "============================================================\n",
      "Sequences: 51,219\n",
      "Goals: 666 (1.3%)\n",
      "Vocab size: 5\n",
      "\n",
      "First sequence:\n",
      "[{'end_x': 0.93, 'end_y': 0.5225, 'type': 'Pass', 'x': 0.70833, 'y': 0.3275}\n",
      " {'end_x': None, 'end_y': None, 'type': 'Shot', 'x': 0.895, 'y': 0.42625}\n",
      " {'end_x': None, 'end_y': None, 'type': 'GOAL', 'x': None, 'y': None}]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_parquet('data/sequences_continuous_train_balanced.parquet')\n",
    "df_val = pd.read_parquet('data/sequences_continuous_val_natural.parquet')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAIN SET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sequences: {len(df_train):,}\")\n",
    "print(f\"Goals: {df_train['goal'].sum():,} ({df_train['goal'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION SET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Sequences: {len(df_val):,}\")\n",
    "print(f\"Goals: {df_val['goal'].sum():,} ({df_val['goal'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Load vocabulary\n",
    "with open('data/vocab_continuous.json', 'r') as f:\n",
    "    type_vocab = json.load(f)\n",
    "\n",
    "with open('data/id_to_type_continuous.json', 'r') as f:\n",
    "    id_to_type = json.load(f)\n",
    "    id_to_type = {int(k): v for k, v in id_to_type.items()}\n",
    "\n",
    "print(f\"Vocab size: {len(type_vocab)}\")\n",
    "print(f\"\\nFirst sequence:\")\n",
    "print(df_train['events'].iloc[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13252d18-9b0a-4b0b-9394-7c5ec96e9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL sequence (last 2 events):\n",
      "[{'end_x': None, 'end_y': None, 'type': 'Shot', 'x': 0.895, 'y': 0.42625}\n",
      " {'end_x': None, 'end_y': None, 'type': 'GOAL', 'x': None, 'y': None}]\n",
      "\n",
      "NO_GOAL sequence (last event):\n",
      "[{'end_x': 0.90417, 'end_y': 0.005, 'type': 'Pass', 'x': 0.5825, 'y': 0.85375}\n",
      " {'end_x': None, 'end_y': None, 'type': 'NO_GOAL', 'x': None, 'y': None}]\n"
     ]
    }
   ],
   "source": [
    "# Pokaż przykład z GOAL i NO_GOAL\n",
    "goal_seq = df_train[df_train['goal'] == 1]['events'].iloc[0]\n",
    "print(f\"\\nGOAL sequence (last 2 events):\")\n",
    "print(goal_seq[-2:])  # powinno być Shot → GOAL\n",
    "\n",
    "no_goal_seq = df_train[df_train['goal'] == 0]['events'].iloc[0]\n",
    "print(f\"\\nNO_GOAL sequence (last event):\")\n",
    "print(no_goal_seq[-2:])  # powinno być Shot/Pass → NO_GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5133f7b5-63bd-4aba-b6bb-3d00334a8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Shot': 3736})\n",
      "Sequence length stats:\n",
      "count    73436.000000\n",
      "mean         5.856719\n",
      "std          3.537457\n",
      "min          2.000000\n",
      "25%          3.000000\n",
      "50%          5.000000\n",
      "75%          8.000000\n",
      "max         13.000000\n",
      "Name: sequence_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sprawdź czy GOAL zawsze po Shot\n",
    "goal_sequences = df_train[df_train['goal'] == 1]['events']\n",
    "\n",
    "shots_before_goal = []\n",
    "for seq in goal_sequences:\n",
    "    if len(seq) >= 2:\n",
    "        shots_before_goal.append(seq[-2]['type'])\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(shots_before_goal))\n",
    "\n",
    "print(f\"Sequence length stats:\")\n",
    "print(df_train['sequence_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74831cec-c076-4969-bd3e-3881bf18d55a",
   "metadata": {},
   "source": [
    "### Przygotowanie danych dla modelu\n",
    "\n",
    "Dataset implementuje causal shift: input to eventy [0, 1, ..., n-1], target to [1, 2, ..., n], gdzie każdy event przewiduje następny. \n",
    "\n",
    "Każdy event reprezentowany jako:\n",
    "- **type_id** - typ zdarzenia (Pass, Shot, GOAL, etc.)\n",
    "- **positions** - wektor [start_x, start_y, end_x, end_y] znormalizowany do [0,1]\n",
    "- **start_mask** - czy event ma pozycję początkową (Pass/Shot mają, GOAL/NO_GOAL nie)\n",
    "- **end_mask** - czy event ma pozycję końcową (tylko Pass)\n",
    "\n",
    "Padding do max_seq_len=14 z ignore_index=-100 dla loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56dc369b-df04-4eee-a6a4-33cd9379fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousXTDataset(Dataset):\n",
    "    def __init__(self, df, type_vocab, max_seq_len=14):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.type_vocab = type_vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        events = row['events']\n",
    "        \n",
    "        # Causal shift: input predicts next token\n",
    "        input_events = events[:-1]   # [0, 1, 2, ..., n-1]\n",
    "        target_events = events[1:]   # [1, 2, 3, ..., n]\n",
    "        \n",
    "        seq_len = len(input_events)  # rzeczywista długość (bez paddingu)\n",
    "\n",
    "        input_type_ids = [self.type_vocab[e['type']] for e in input_events]\n",
    "        target_type_ids = [self.type_vocab[e['type']] for e in target_events]\n",
    "\n",
    "        # Build position tensors [start_x, start_y, end_x, end_y]\n",
    "        def _build_positions(events_list):\n",
    "            positions = []\n",
    "            for e in events_list:\n",
    "                pos = [\n",
    "                    e['x'] if e['x'] is not None else 0.0,\n",
    "                    e['y'] if e['y'] is not None else 0.0,\n",
    "                    e['end_x'] if e['end_x'] is not None else 0.0,\n",
    "                    e['end_y'] if e['end_y'] is not None else 0.0\n",
    "                ]\n",
    "                positions.append(pos)\n",
    "            return positions\n",
    "\n",
    "        input_positions = _build_positions(input_events)\n",
    "        target_positions = _build_positions(target_events)\n",
    "\n",
    "        # Build masks\n",
    "        def _build_masks(events_list):\n",
    "            start_masks = []\n",
    "            end_masks = []\n",
    "            for e in events_list:\n",
    "                # start_mask: True if event has position (Pass/Shot)\n",
    "                has_start = e['x'] is not None\n",
    "                start_masks.append(has_start)\n",
    "                \n",
    "                # end_mask: True only for Pass (has end_x, end_y)\n",
    "                has_end = e['end_x'] is not None\n",
    "                end_masks.append(has_end)\n",
    "            \n",
    "            return start_masks, end_masks\n",
    "        \n",
    "        input_start_mask, input_end_mask = _build_masks(input_events)\n",
    "        target_start_mask, target_end_mask = _build_masks(target_events)\n",
    "\n",
    "        # Padding\n",
    "        pad_len = self.max_seq_len - seq_len\n",
    "        \n",
    "        # Pad type IDs\n",
    "        input_type_ids += [self.type_vocab['<pad>']] * pad_len\n",
    "        target_type_ids += [-100] * pad_len  # ignore_index for loss\n",
    "        \n",
    "        # Pad positions (zeros)\n",
    "        input_positions += [[0.0, 0.0, 0.0, 0.0]] * pad_len\n",
    "        target_positions += [[0.0, 0.0, 0.0, 0.0]] * pad_len\n",
    "        \n",
    "        # Pad masks (False)\n",
    "        input_start_mask += [False] * pad_len\n",
    "        input_end_mask += [False] * pad_len\n",
    "        target_start_mask += [False] * pad_len\n",
    "        target_end_mask += [False] * pad_len\n",
    "        \n",
    "        # Convert to tensors\n",
    "        return {\n",
    "            'input_types': torch.tensor(input_type_ids, dtype=torch.long),\n",
    "            'input_positions': torch.tensor(input_positions, dtype=torch.float32),\n",
    "            'input_start_mask': torch.tensor(input_start_mask, dtype=torch.bool),\n",
    "            'input_end_mask': torch.tensor(input_end_mask, dtype=torch.bool),\n",
    "            \n",
    "            'target_types': torch.tensor(target_type_ids, dtype=torch.long),\n",
    "            'target_positions': torch.tensor(target_positions, dtype=torch.float32),\n",
    "            'target_start_mask': torch.tensor(target_start_mask, dtype=torch.bool),\n",
    "            'target_end_mask': torch.tensor(target_end_mask, dtype=torch.bool)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "040395bb-b33b-4152-959f-76f842b4873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 73436\n",
      "Val size: 51219\n",
      "\n",
      "Sample shapes:\n",
      "  input_types: torch.Size([14]) (torch.int64)\n",
      "  input_positions: torch.Size([14, 4]) (torch.float32)\n",
      "  input_start_mask: torch.Size([14]) (torch.bool)\n",
      "  input_end_mask: torch.Size([14]) (torch.bool)\n",
      "  target_types: torch.Size([14]) (torch.int64)\n",
      "  target_positions: torch.Size([14, 4]) (torch.float32)\n",
      "  target_start_mask: torch.Size([14]) (torch.bool)\n",
      "  target_end_mask: torch.Size([14]) (torch.bool)\n",
      "\n",
      "Input types: tensor([0, 1, 4, 4, 4])\n",
      "Target types: tensor([   1,    2, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "train_dataset = ContinuousXTDataset(df_train, type_vocab)\n",
    "val_dataset = ContinuousXTDataset(df_val, type_vocab)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "\n",
    "# Test jednej próbki\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"  {k}: {v.shape} ({v.dtype})\")\n",
    "\n",
    "print(f\"\\nInput types: {sample['input_types'][:5]}\")\n",
    "print(f\"Target types: {sample['target_types'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da963c0-fca5-4578-9de2-05392d50295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch shapes:\n",
      "  input_types: torch.Size([32, 14])\n",
      "  input_positions: torch.Size([32, 14, 4])\n",
      "  input_start_mask: torch.Size([32, 14])\n",
      "  input_end_mask: torch.Size([32, 14])\n",
      "  target_types: torch.Size([32, 14])\n",
      "  target_positions: torch.Size([32, 14, 4])\n",
      "  target_start_mask: torch.Size([32, 14])\n",
      "  target_end_mask: torch.Size([32, 14])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"  {k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8eefa1-8b1f-471f-b850-75436b8384a2",
   "metadata": {},
   "source": [
    "### Fourier Position Encoding\n",
    "\n",
    "Zamiast standardowego embedowania współrzędnych, używamy kodowania Fouriera dla 4 współrzędnych [start_x, start_y, end_x, end_y]:\n",
    "- 8 częstotliwości: [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "- sin i cos dla każdej częstotliwości → 4 coords × 8 freqs × 2 = 64 cechy\n",
    "- Projekcja liniowa do d_model=512\n",
    "\n",
    "Fourier features pozwalają na płynną interpolację przestrzenną - model lepiej rozumie podobieństwo pozycji bliskich sobie na boisku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1088820d-3204-4213-903a-4de6c9376dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierPositionEncoder(nn.Module):\n",
    "    def __init__(self, freqs=[1,2,4,8,16,32,64,128], d_model=512):\n",
    "        super().__init__()\n",
    "        self.freqs = torch.tensor(freqs, dtype=torch.float32)\n",
    "        # 4 coords × 8 freqs × 2 (sin/cos) = 64\n",
    "        self.proj = nn.Linear(64, d_model)\n",
    "    \n",
    "    def forward(self, pos):\n",
    "        # pos: [B, T, 4]\n",
    "        B, T, _ = pos.shape\n",
    "        \n",
    "        # Expand: [B,T,4] → [B,T,4,1] × [8] → [B,T,4,8]\n",
    "        freqs = self.freqs.to(pos.device)\n",
    "        pos_expanded = pos.unsqueeze(-1)  # [B,T,4,1]\n",
    "        angles = pos_expanded * freqs  # [B,T,4,8]\n",
    "        \n",
    "        # sin/cos\n",
    "        sin_features = torch.sin(angles)  # [B,T,4,8]\n",
    "        cos_features = torch.cos(angles)  # [B,T,4,8]\n",
    "        \n",
    "        # Flatten: [B,T,4,8,2] → [B,T,64]\n",
    "        fourier = torch.stack([sin_features, cos_features], dim=-1)  # [B,T,4,8,2]\n",
    "        fourier = fourier.reshape(B, T, -1)  # [B,T,64]\n",
    "        \n",
    "        return self.proj(fourier)  # [B,T,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804d7fdd-914a-410a-837c-3d856d2a5b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder = FourierPositionEncoder()\n",
    "pos = torch.rand(2, 5, 4)  # batch=2, seq=5\n",
    "out = encoder(pos)\n",
    "print(out.shape)  # torch.Size([2, 5, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a222d99-6938-469f-a94e-bdf7fd5f9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([2, 5, 4])\n",
      "Output: torch.Size([2, 5, 512])\n",
      "Sample values: tensor([-0.4461, -0.0095,  0.1573,  0.2313, -0.8890], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_pos = batch['input_positions'][:2, :5]  # [2, 5, 4]\n",
    "encoded = encoder(sample_pos)\n",
    "print(f\"Input: {sample_pos.shape}\")\n",
    "print(f\"Output: {encoded.shape}\")\n",
    "print(f\"Sample values: {encoded[0,0,:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ecf80a-a57b-4110-a8ba-3b0e0d190d80",
   "metadata": {},
   "source": [
    "### Architektura modelu: Transformer + MDN\n",
    "\n",
    "Model składa się z:\n",
    "1. **Embeddings**: type embedding + Fourier position encoding\n",
    "2. **Transformer encoder** z causal masking (12 warstw, 8 head, d_model=512)\n",
    "3. **Dwie głowice predykcyjne**:\n",
    "   - Type head: logity dla vocab_size=7 (Pass, Shot, GOAL, etc.)\n",
    "   - MDN head: parametry dla n_components=5 Gaussianów (8 parametrów × 5 = 40 wartości)\n",
    "\n",
    "MDN przewiduje rozkład prawdopodobieństwa pozycji jako mieszankę 5 Gaussianów, każdy z wagą i parametrami dla start position (μ, σ) oraz end position (μx, μy, σx, σy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb115d0c-191f-435f-b024-7c72dd550006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousXTModel(nn.Module):\n",
    "    def __init__(self, vocab_size=6, d_model=512, nhead=8, num_layers=12, n_components=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_components = n_components  # Zapisz jako atrybut\n",
    "        \n",
    "        # Embeddings\n",
    "        self.type_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoder = FourierPositionEncoder(d_model=d_model)\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=2048,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Prediction heads\n",
    "        self.type_head = nn.Linear(d_model, vocab_size)\n",
    "        self.mdn_head = nn.Linear(d_model, n_components * 8)  # n_components × 8\n",
    "    \n",
    "    def forward(self, types, positions, start_mask):\n",
    "        # Embeddings\n",
    "        type_emb = self.type_embedding(types)\n",
    "        pos_emb = self.position_encoder(positions)\n",
    "        \n",
    "        # Mask positions for GOAL/NO_GOAL\n",
    "        pos_emb = pos_emb * start_mask.unsqueeze(-1).float()\n",
    "        combined = type_emb + pos_emb\n",
    "        \n",
    "        # Causal mask\n",
    "        T = types.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(T, T), diagonal=1).bool().to(types.device)\n",
    "        \n",
    "        # Transformer\n",
    "        hidden = self.transformer(combined, mask=causal_mask)\n",
    "        \n",
    "        # Predictions\n",
    "        type_logits = self.type_head(hidden)\n",
    "        mdn_params = self.mdn_head(hidden).view(types.size(0), T, self.n_components, 8)  # [B,T,n_components,8]\n",
    "        \n",
    "        return type_logits, mdn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00b3fc05-9c6d-4163-a9d1-dc9c509554a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type logits: torch.Size([4, 14, 6])\n",
      "MDN params: torch.Size([4, 14, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "model = ContinuousXTModel(n_components=6)\n",
    "type_logits, mdn_params = model(\n",
    "    batch['input_types'][:4],\n",
    "    batch['input_positions'][:4],\n",
    "    batch['input_start_mask'][:4]\n",
    ")\n",
    "print(f\"Type logits: {type_logits.shape}\")\n",
    "print(f\"MDN params: {mdn_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1482d734-3508-4555-bd53-b199ca9923ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mdn_params(mdn_params):\n",
    "    \"\"\"\n",
    "    mdn_params: [B, T, 5, 8]\n",
    "    Returns: dict with weights and distributions\n",
    "    \"\"\"\n",
    "    # Extract components\n",
    "    weights = torch.nn.functional.softmax(mdn_params[..., 0], dim=-1)  # [B,T,5] - sum to 1\n",
    "    \n",
    "    # Start position (μ, σ)\n",
    "    start_mean_x = torch.sigmoid(mdn_params[..., 1])  # [B,T,5] in [0,1]\n",
    "    start_mean_y = torch.sigmoid(mdn_params[..., 2])\n",
    "    start_std = torch.exp(mdn_params[..., 3]).clamp(0.005, 0.1)  # small variance\n",
    "    \n",
    "    # End position (μx, μy, σx, σy)\n",
    "    end_mean_x = torch.sigmoid(mdn_params[..., 4])\n",
    "    end_mean_y = torch.sigmoid(mdn_params[..., 5])\n",
    "    end_std_x = torch.exp(mdn_params[..., 6]).clamp(0.01, 0.5)  # wider variance\n",
    "    end_std_y = torch.exp(mdn_params[..., 7]).clamp(0.01, 0.5)\n",
    "    \n",
    "    return {\n",
    "        'weights': weights,\n",
    "        'start_mean': torch.stack([start_mean_x, start_mean_y], dim=-1),  # [B,T,5,2]\n",
    "        'start_std': start_std,  # [B,T,5]\n",
    "        'end_mean': torch.stack([end_mean_x, end_mean_y], dim=-1),  # [B,T,5,2]\n",
    "        'end_std': torch.stack([end_std_x, end_std_y], dim=-1)  # [B,T,5,2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d641403f-f649-4a09-a9f8-c105888fb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: torch.Size([4, 14, 6])\n",
      "start_mean: torch.Size([4, 14, 6, 2])\n",
      "start_std: torch.Size([4, 14, 6])\n",
      "end_mean: torch.Size([4, 14, 6, 2])\n",
      "end_std: torch.Size([4, 14, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "parsed = parse_mdn_params(mdn_params)\n",
    "for k, v in parsed.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed053b-f351-4eac-aeb7-5444ada3f577",
   "metadata": {},
   "source": [
    "### Funkcje straty z wagami dla imbalance\n",
    "\n",
    "**Type loss**: Weighted CrossEntropy, wagi dostosowane do częstości:\n",
    "- GOAL: 30.0 (rzadkie, bardzo ważne)\n",
    "- Shot: 10.0 (rzadkie)\n",
    "- NO_GOAL: 2.0 (częste)\n",
    "- Pass: 1.0 (bardzo częste, baseline)\n",
    "\n",
    "**MDN loss**: Negative log-likelihood mieszanki Gaussianów\n",
    "- Model uczy się przewidywać rozkład pozycji, nie punktowe wartości\n",
    "- Dla każdego komponentu: waga × prawdopodobieństwo pod rozkładem\n",
    "- Maskujemy pozycje dla GOAL/NO_GOAL (nie mają współrzędnych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c340b203-dd5f-4b76-a891-9d50a960a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_CONFIG = {\n",
    "    \"START\": 1.0,\n",
    "    \"Pass\": 1.0,\n",
    "    \"Shot\": 5.0,\n",
    "    \"GOAL\": 15.0,\n",
    "    \"NO_GOAL\": 1.0,\n",
    "    \"<pad>\": 1.0\n",
    "}\n",
    "\n",
    "\n",
    "def type_loss(type_logits, target_types):\n",
    "    # Wagi z config\n",
    "    weights = torch.tensor([\n",
    "        WEIGHT_CONFIG[\"START\"],\n",
    "        WEIGHT_CONFIG[\"Pass\"],\n",
    "        WEIGHT_CONFIG[\"Shot\"],\n",
    "        WEIGHT_CONFIG[\"GOAL\"],\n",
    "        WEIGHT_CONFIG[\"NO_GOAL\"],\n",
    "        WEIGHT_CONFIG[\"<pad>\"]\n",
    "    ]).to(type_logits.device)\n",
    "    \n",
    "    return F.cross_entropy(\n",
    "        type_logits.reshape(-1, 6),\n",
    "        target_types.reshape(-1),\n",
    "        weight=weights,\n",
    "        ignore_index=-100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9efc802-eb21-4648-a281-de7457cc19a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pass': 0, 'Shot': 1, 'GOAL': 2, 'NO_GOAL': 3, '<pad>': 4}\n",
      "{0: 'Pass', 1: 'Shot', 2: 'GOAL', 3: 'NO_GOAL', 4: '<pad>'}\n"
     ]
    }
   ],
   "source": [
    "print(type_vocab)\n",
    "print(id_to_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870bd3a8-816a-417c-8186-2596161723f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll(target, mean, std):\n",
    "    \"\"\"Negative log-likelihood of Gaussian\"\"\"\n",
    "    variance = std ** 2\n",
    "    return 0.5 * (torch.log(2 * torch.pi * variance) + ((target - mean) ** 2) / variance)\n",
    "\n",
    "def mdn_loss(mdn_params, target_positions, target_start_mask, target_end_mask):\n",
    "    \"\"\"\n",
    "    mdn_params: [B, T, n_components, 8]\n",
    "    target_positions: [B, T, 4] - [start_x, start_y, end_x, end_y]\n",
    "    \"\"\"\n",
    "    parsed = parse_mdn_params(mdn_params)\n",
    "    B, T, n_components = mdn_params.shape[:3]  # Dynamicznie pobierz n_components\n",
    "    \n",
    "    # Target positions\n",
    "    target_start = target_positions[..., :2]  # [B,T,2]\n",
    "    target_end = target_positions[..., 2:]    # [B,T,2]\n",
    "    \n",
    "    # Compute NLL for each component\n",
    "    component_nll = []\n",
    "    for k in range(n_components):  # 5 → n_components\n",
    "        # Start NLL\n",
    "        start_nll = gaussian_nll(\n",
    "            target_start.unsqueeze(2),\n",
    "            parsed['start_mean'][:, :, k:k+1, :],\n",
    "            parsed['start_std'][:, :, k:k+1].unsqueeze(-1)\n",
    "        ).sum(dim=-1)\n",
    "        \n",
    "        # End NLL\n",
    "        end_nll = gaussian_nll(\n",
    "            target_end.unsqueeze(2),\n",
    "            parsed['end_mean'][:, :, k:k+1, :],\n",
    "            parsed['end_std'][:, :, k:k+1, :]\n",
    "        ).sum(dim=-1)\n",
    "        \n",
    "        component_nll.append(start_nll + end_nll)\n",
    "    \n",
    "    component_nll = torch.cat(component_nll, dim=-1)  # [B,T,n_components]\n",
    "    \n",
    "    # Mixture NLL\n",
    "    log_weights = torch.log(parsed['weights'] + 1e-8)\n",
    "    mixture_nll = -torch.logsumexp(log_weights - component_nll, dim=-1)\n",
    "    \n",
    "    # Mask\n",
    "    mask = target_start_mask.float()\n",
    "    return (mixture_nll * mask).sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1160126-5fad-41f3-b9f7-d4628d16fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type loss: 2.3751\n",
      "MDN loss: 0.9919\n"
     ]
    }
   ],
   "source": [
    "type_l = type_loss(type_logits, batch['target_types'][:4])\n",
    "mdn_l = mdn_loss(mdn_params, batch['target_positions'][:4], \n",
    "                 batch['target_start_mask'][:4], batch['target_end_mask'][:4])\n",
    "print(f\"Type loss: {type_l.item():.4f}\")\n",
    "print(f\"MDN loss: {mdn_l.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30489260-0b7a-46ea-8357-981673d7b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined loss\n",
    "def combined_loss(model, batch):\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "    \n",
    "    t_loss = type_loss(type_logits, batch['target_types'])\n",
    "    m_loss = mdn_loss(\n",
    "        mdn_params, \n",
    "        batch['target_positions'],\n",
    "        batch['target_start_mask'],\n",
    "        batch['target_end_mask']\n",
    "    )\n",
    "    \n",
    "    return t_loss + m_loss, t_loss, m_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729f546-4cf6-40b7-90ab-63a95aa32bbc",
   "metadata": {},
   "source": [
    "### Trening modelu\n",
    "\n",
    "Hiperparametry:\n",
    "- **Optimizer**: AdamW (lr=1e-4, weight_decay=0.01)\n",
    "- **Batch size**: 32\n",
    "- **Epochs**: 10\n",
    "- **Gradient clipping**: 1.0 (stabilizacja)\n",
    "- **Loss**: type_loss + mdn_loss (suma)\n",
    "\n",
    "Model trenowany na ~14.6k sekwencji (85% zbioru), walidacja na ~2.6k (15%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ac2ca2-8634-4e9a-8c8a-91a02e61b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 5.4809 (type: 1.499, mdn: 3.982)\n",
      "Epoch 1, Batch 100, Loss: 0.2183 (type: 0.556, mdn: -0.337)\n",
      "Epoch 1, Batch 200, Loss: -1.5495 (type: 0.493, mdn: -2.042)\n",
      "Epoch 1, Batch 300, Loss: -1.8716 (type: 0.624, mdn: -2.495)\n",
      "Epoch 1, Batch 400, Loss: -2.1230 (type: 0.537, mdn: -2.660)\n",
      "Epoch 1, Batch 500, Loss: -2.5854 (type: 0.466, mdn: -3.051)\n",
      "Epoch 1, Batch 600, Loss: -2.2863 (type: 0.512, mdn: -2.798)\n",
      "Epoch 1, Batch 700, Loss: -2.6474 (type: 0.489, mdn: -3.136)\n",
      "Epoch 1, Batch 800, Loss: -2.5677 (type: 0.445, mdn: -3.013)\n",
      "Epoch 1, Batch 900, Loss: -2.5586 (type: 0.577, mdn: -3.136)\n",
      "Epoch 1, Batch 1000, Loss: -2.4705 (type: 0.543, mdn: -3.013)\n",
      "Epoch 1, Batch 1100, Loss: -2.6077 (type: 0.556, mdn: -3.164)\n",
      "Epoch 1, Batch 1200, Loss: -2.7489 (type: 0.484, mdn: -3.233)\n",
      "Epoch 1, Batch 1300, Loss: -2.7096 (type: 0.444, mdn: -3.154)\n",
      "Epoch 1, Batch 1400, Loss: -2.5864 (type: 0.501, mdn: -3.088)\n",
      "Epoch 1, Batch 1500, Loss: -2.7270 (type: 0.498, mdn: -3.225)\n",
      "Epoch 1, Batch 1600, Loss: -2.4989 (type: 0.459, mdn: -2.958)\n",
      "Epoch 1, Batch 1700, Loss: -2.4249 (type: 0.468, mdn: -2.893)\n",
      "Epoch 1, Batch 1800, Loss: -2.5757 (type: 0.463, mdn: -3.039)\n",
      "Epoch 1, Batch 1900, Loss: -2.9329 (type: 0.516, mdn: -3.449)\n",
      "Epoch 1, Batch 2000, Loss: -2.4442 (type: 0.527, mdn: -2.972)\n",
      "Epoch 1, Batch 2100, Loss: -2.6594 (type: 0.509, mdn: -3.168)\n",
      "Epoch 1, Batch 2200, Loss: -2.8652 (type: 0.481, mdn: -3.346)\n",
      "Epoch 1 avg loss: -2.3172\n",
      "Epoch 2, Batch 0, Loss: -2.6309 (type: 0.421, mdn: -3.052)\n",
      "Epoch 2, Batch 100, Loss: -2.6296 (type: 0.380, mdn: -3.010)\n",
      "Epoch 2, Batch 200, Loss: -2.6934 (type: 0.498, mdn: -3.191)\n",
      "Epoch 2, Batch 300, Loss: -2.6633 (type: 0.461, mdn: -3.124)\n",
      "Epoch 2, Batch 400, Loss: -2.4118 (type: 0.595, mdn: -3.007)\n",
      "Epoch 2, Batch 500, Loss: -2.7567 (type: 0.517, mdn: -3.273)\n",
      "Epoch 2, Batch 600, Loss: -2.7559 (type: 0.454, mdn: -3.210)\n",
      "Epoch 2, Batch 700, Loss: -2.9009 (type: 0.455, mdn: -3.355)\n",
      "Epoch 2, Batch 800, Loss: -2.5452 (type: 0.529, mdn: -3.074)\n",
      "Epoch 2, Batch 900, Loss: -2.5837 (type: 0.532, mdn: -3.116)\n",
      "Epoch 2, Batch 1000, Loss: -2.7380 (type: 0.467, mdn: -3.205)\n",
      "Epoch 2, Batch 1100, Loss: -2.6344 (type: 0.588, mdn: -3.222)\n",
      "Epoch 2, Batch 1200, Loss: -3.1323 (type: 0.539, mdn: -3.672)\n",
      "Epoch 2, Batch 1300, Loss: -2.9494 (type: 0.553, mdn: -3.503)\n",
      "Epoch 2, Batch 1400, Loss: -2.6292 (type: 0.515, mdn: -3.145)\n",
      "Epoch 2, Batch 1500, Loss: -2.3775 (type: 0.460, mdn: -2.838)\n",
      "Epoch 2, Batch 1600, Loss: -2.6983 (type: 0.493, mdn: -3.191)\n",
      "Epoch 2, Batch 1700, Loss: -2.6948 (type: 0.429, mdn: -3.124)\n",
      "Epoch 2, Batch 1800, Loss: -2.5612 (type: 0.462, mdn: -3.024)\n",
      "Epoch 2, Batch 1900, Loss: -2.8040 (type: 0.388, mdn: -3.192)\n",
      "Epoch 2, Batch 2000, Loss: -2.5330 (type: 0.385, mdn: -2.918)\n",
      "Epoch 2, Batch 2100, Loss: -2.9919 (type: 0.484, mdn: -3.476)\n",
      "Epoch 2, Batch 2200, Loss: -2.9420 (type: 0.455, mdn: -3.397)\n",
      "Epoch 2 avg loss: -2.7826\n",
      "Epoch 3, Batch 0, Loss: -2.7694 (type: 0.482, mdn: -3.251)\n",
      "Epoch 3, Batch 100, Loss: -2.9269 (type: 0.444, mdn: -3.371)\n",
      "Epoch 3, Batch 200, Loss: -3.2256 (type: 0.400, mdn: -3.625)\n",
      "Epoch 3, Batch 300, Loss: -3.3335 (type: 0.430, mdn: -3.764)\n",
      "Epoch 3, Batch 400, Loss: -2.8474 (type: 0.443, mdn: -3.291)\n",
      "Epoch 3, Batch 500, Loss: -3.0383 (type: 0.528, mdn: -3.566)\n",
      "Epoch 3, Batch 600, Loss: -3.0927 (type: 0.470, mdn: -3.563)\n",
      "Epoch 3, Batch 700, Loss: -2.9561 (type: 0.397, mdn: -3.353)\n",
      "Epoch 3, Batch 800, Loss: -2.9562 (type: 0.456, mdn: -3.412)\n",
      "Epoch 3, Batch 900, Loss: -2.5558 (type: 0.572, mdn: -3.128)\n",
      "Epoch 3, Batch 1000, Loss: -2.7009 (type: 0.488, mdn: -3.189)\n",
      "Epoch 3, Batch 1100, Loss: -2.9205 (type: 0.469, mdn: -3.389)\n",
      "Epoch 3, Batch 1200, Loss: -2.8774 (type: 0.464, mdn: -3.341)\n",
      "Epoch 3, Batch 1300, Loss: -2.6925 (type: 0.536, mdn: -3.229)\n",
      "Epoch 3, Batch 1400, Loss: -3.0045 (type: 0.577, mdn: -3.582)\n",
      "Epoch 3, Batch 1500, Loss: -2.6153 (type: 0.512, mdn: -3.128)\n",
      "Epoch 3, Batch 1600, Loss: -2.7067 (type: 0.505, mdn: -3.212)\n",
      "Epoch 3, Batch 1700, Loss: -2.8406 (type: 0.467, mdn: -3.307)\n",
      "Epoch 3, Batch 1800, Loss: -3.1059 (type: 0.368, mdn: -3.474)\n",
      "Epoch 3, Batch 1900, Loss: -3.0151 (type: 0.434, mdn: -3.449)\n",
      "Epoch 3, Batch 2000, Loss: -2.8707 (type: 0.486, mdn: -3.357)\n",
      "Epoch 3, Batch 2100, Loss: -2.9436 (type: 0.453, mdn: -3.396)\n",
      "Epoch 3, Batch 2200, Loss: -2.9851 (type: 0.375, mdn: -3.360)\n",
      "Epoch 3 avg loss: -2.8549\n",
      "Epoch 4, Batch 0, Loss: -2.9258 (type: 0.423, mdn: -3.349)\n",
      "Epoch 4, Batch 100, Loss: -2.7142 (type: 0.440, mdn: -3.154)\n",
      "Epoch 4, Batch 200, Loss: -2.7283 (type: 0.405, mdn: -3.133)\n",
      "Epoch 4, Batch 300, Loss: -2.4840 (type: 0.475, mdn: -2.959)\n",
      "Epoch 4, Batch 400, Loss: -3.0116 (type: 0.507, mdn: -3.518)\n",
      "Epoch 4, Batch 500, Loss: -2.4789 (type: 0.459, mdn: -2.938)\n",
      "Epoch 4, Batch 600, Loss: -3.0390 (type: 0.419, mdn: -3.458)\n",
      "Epoch 4, Batch 700, Loss: -2.6696 (type: 0.494, mdn: -3.164)\n",
      "Epoch 4, Batch 800, Loss: -2.8966 (type: 0.466, mdn: -3.362)\n",
      "Epoch 4, Batch 900, Loss: -2.8705 (type: 0.481, mdn: -3.351)\n",
      "Epoch 4, Batch 1000, Loss: -2.8098 (type: 0.437, mdn: -3.247)\n",
      "Epoch 4, Batch 1100, Loss: -2.8157 (type: 0.537, mdn: -3.352)\n",
      "Epoch 4, Batch 1200, Loss: -3.0336 (type: 0.516, mdn: -3.549)\n",
      "Epoch 4, Batch 1300, Loss: -3.1889 (type: 0.400, mdn: -3.589)\n",
      "Epoch 4, Batch 1400, Loss: -2.4816 (type: 0.450, mdn: -2.931)\n",
      "Epoch 4, Batch 1500, Loss: -2.7854 (type: 0.516, mdn: -3.301)\n",
      "Epoch 4, Batch 1600, Loss: -3.1943 (type: 0.375, mdn: -3.569)\n",
      "Epoch 4, Batch 1700, Loss: -2.5430 (type: 0.421, mdn: -2.964)\n",
      "Epoch 4, Batch 1800, Loss: -2.6577 (type: 0.500, mdn: -3.158)\n",
      "Epoch 4, Batch 1900, Loss: -3.0770 (type: 0.390, mdn: -3.467)\n",
      "Epoch 4, Batch 2000, Loss: -2.4066 (type: 0.465, mdn: -2.872)\n",
      "Epoch 4, Batch 2100, Loss: -2.9242 (type: 0.433, mdn: -3.357)\n",
      "Epoch 4, Batch 2200, Loss: -3.0992 (type: 0.437, mdn: -3.536)\n",
      "Epoch 4 avg loss: -2.9007\n",
      "Epoch 5, Batch 0, Loss: -2.9586 (type: 0.495, mdn: -3.453)\n",
      "Epoch 5, Batch 100, Loss: -2.6601 (type: 0.484, mdn: -3.144)\n",
      "Epoch 5, Batch 200, Loss: -3.2398 (type: 0.503, mdn: -3.742)\n",
      "Epoch 5, Batch 300, Loss: -2.8890 (type: 0.474, mdn: -3.363)\n",
      "Epoch 5, Batch 400, Loss: -3.0055 (type: 0.501, mdn: -3.507)\n",
      "Epoch 5, Batch 500, Loss: -3.0044 (type: 0.405, mdn: -3.409)\n",
      "Epoch 5, Batch 600, Loss: -2.7372 (type: 0.369, mdn: -3.107)\n",
      "Epoch 5, Batch 700, Loss: -2.4658 (type: 0.421, mdn: -2.887)\n",
      "Epoch 5, Batch 800, Loss: -2.6934 (type: 0.484, mdn: -3.178)\n",
      "Epoch 5, Batch 900, Loss: -3.0776 (type: 0.431, mdn: -3.508)\n",
      "Epoch 5, Batch 1000, Loss: -2.9716 (type: 0.462, mdn: -3.433)\n",
      "Epoch 5, Batch 1100, Loss: -3.0932 (type: 0.481, mdn: -3.574)\n",
      "Epoch 5, Batch 1200, Loss: -3.0032 (type: 0.482, mdn: -3.485)\n",
      "Epoch 5, Batch 1300, Loss: -3.1580 (type: 0.451, mdn: -3.609)\n",
      "Epoch 5, Batch 1400, Loss: -2.9797 (type: 0.414, mdn: -3.394)\n",
      "Epoch 5, Batch 1500, Loss: -2.7689 (type: 0.382, mdn: -3.151)\n",
      "Epoch 5, Batch 1600, Loss: -3.0929 (type: 0.449, mdn: -3.542)\n",
      "Epoch 5, Batch 1700, Loss: -3.1854 (type: 0.506, mdn: -3.692)\n",
      "Epoch 5, Batch 1800, Loss: -2.5915 (type: 0.489, mdn: -3.080)\n",
      "Epoch 5, Batch 1900, Loss: -2.9135 (type: 0.489, mdn: -3.403)\n",
      "Epoch 5, Batch 2000, Loss: -2.8158 (type: 0.474, mdn: -3.290)\n",
      "Epoch 5, Batch 2100, Loss: -2.9950 (type: 0.454, mdn: -3.449)\n",
      "Epoch 5, Batch 2200, Loss: -2.9554 (type: 0.474, mdn: -3.429)\n",
      "Epoch 5 avg loss: -2.9335\n",
      "Epoch 6, Batch 0, Loss: -2.8260 (type: 0.506, mdn: -3.332)\n",
      "Epoch 6, Batch 100, Loss: -3.0634 (type: 0.448, mdn: -3.511)\n",
      "Epoch 6, Batch 200, Loss: -2.6880 (type: 0.480, mdn: -3.168)\n",
      "Epoch 6, Batch 300, Loss: -3.2282 (type: 0.398, mdn: -3.626)\n",
      "Epoch 6, Batch 400, Loss: -2.8214 (type: 0.459, mdn: -3.280)\n",
      "Epoch 6, Batch 500, Loss: -3.3619 (type: 0.553, mdn: -3.915)\n",
      "Epoch 6, Batch 600, Loss: -2.9299 (type: 0.527, mdn: -3.457)\n",
      "Epoch 6, Batch 700, Loss: -3.2382 (type: 0.453, mdn: -3.692)\n",
      "Epoch 6, Batch 800, Loss: -2.7737 (type: 0.511, mdn: -3.285)\n",
      "Epoch 6, Batch 900, Loss: -3.2776 (type: 0.421, mdn: -3.699)\n",
      "Epoch 6, Batch 1000, Loss: -3.0691 (type: 0.457, mdn: -3.526)\n",
      "Epoch 6, Batch 1100, Loss: -2.8612 (type: 0.447, mdn: -3.309)\n",
      "Epoch 6, Batch 1200, Loss: -2.6256 (type: 0.535, mdn: -3.161)\n",
      "Epoch 6, Batch 1300, Loss: -3.0031 (type: 0.434, mdn: -3.437)\n",
      "Epoch 6, Batch 1400, Loss: -3.0220 (type: 0.494, mdn: -3.516)\n",
      "Epoch 6, Batch 1500, Loss: -2.9995 (type: 0.479, mdn: -3.478)\n",
      "Epoch 6, Batch 1600, Loss: -3.0369 (type: 0.404, mdn: -3.441)\n",
      "Epoch 6, Batch 1700, Loss: -3.0078 (type: 0.327, mdn: -3.335)\n",
      "Epoch 6, Batch 1800, Loss: -2.9151 (type: 0.455, mdn: -3.370)\n",
      "Epoch 6, Batch 1900, Loss: -3.2277 (type: 0.448, mdn: -3.675)\n",
      "Epoch 6, Batch 2000, Loss: -3.0025 (type: 0.467, mdn: -3.469)\n",
      "Epoch 6, Batch 2100, Loss: -3.0984 (type: 0.441, mdn: -3.540)\n",
      "Epoch 6, Batch 2200, Loss: -3.1253 (type: 0.395, mdn: -3.520)\n",
      "Epoch 6 avg loss: -2.9616\n",
      "Epoch 7, Batch 0, Loss: -3.4225 (type: 0.427, mdn: -3.849)\n",
      "Epoch 7, Batch 100, Loss: -2.1865 (type: 0.528, mdn: -2.714)\n",
      "Epoch 7, Batch 200, Loss: -2.5518 (type: 0.412, mdn: -2.963)\n",
      "Epoch 7, Batch 300, Loss: -3.1197 (type: 0.416, mdn: -3.536)\n",
      "Epoch 7, Batch 400, Loss: -3.0144 (type: 0.391, mdn: -3.405)\n",
      "Epoch 7, Batch 500, Loss: -2.7624 (type: 0.488, mdn: -3.250)\n",
      "Epoch 7, Batch 600, Loss: -2.5306 (type: 0.379, mdn: -2.909)\n",
      "Epoch 7, Batch 700, Loss: -3.0257 (type: 0.494, mdn: -3.520)\n",
      "Epoch 7, Batch 800, Loss: -2.8932 (type: 0.538, mdn: -3.431)\n",
      "Epoch 7, Batch 900, Loss: -3.0523 (type: 0.442, mdn: -3.495)\n",
      "Epoch 7, Batch 1000, Loss: -2.8843 (type: 0.507, mdn: -3.391)\n",
      "Epoch 7, Batch 1100, Loss: -2.8572 (type: 0.448, mdn: -3.305)\n",
      "Epoch 7, Batch 1200, Loss: -2.9924 (type: 0.512, mdn: -3.504)\n",
      "Epoch 7, Batch 1300, Loss: -3.2249 (type: 0.384, mdn: -3.609)\n",
      "Epoch 7, Batch 1400, Loss: -2.8128 (type: 0.526, mdn: -3.339)\n",
      "Epoch 7, Batch 1500, Loss: -2.9721 (type: 0.455, mdn: -3.427)\n",
      "Epoch 7, Batch 1600, Loss: -2.9609 (type: 0.372, mdn: -3.333)\n",
      "Epoch 7, Batch 1700, Loss: -3.2645 (type: 0.337, mdn: -3.601)\n",
      "Epoch 7, Batch 1800, Loss: -3.1525 (type: 0.521, mdn: -3.673)\n",
      "Epoch 7, Batch 1900, Loss: -2.8601 (type: 0.466, mdn: -3.326)\n",
      "Epoch 7, Batch 2000, Loss: -3.2020 (type: 0.445, mdn: -3.647)\n",
      "Epoch 7, Batch 2100, Loss: -2.6118 (type: 0.597, mdn: -3.209)\n",
      "Epoch 7, Batch 2200, Loss: -2.8452 (type: 0.521, mdn: -3.367)\n",
      "Epoch 7 avg loss: -2.9824\n",
      "Epoch 8, Batch 0, Loss: -3.3681 (type: 0.451, mdn: -3.819)\n",
      "Epoch 8, Batch 100, Loss: -2.9348 (type: 0.360, mdn: -3.295)\n",
      "Epoch 8, Batch 200, Loss: -3.4158 (type: 0.485, mdn: -3.901)\n",
      "Epoch 8, Batch 300, Loss: -3.0803 (type: 0.397, mdn: -3.478)\n",
      "Epoch 8, Batch 400, Loss: -3.1612 (type: 0.393, mdn: -3.554)\n",
      "Epoch 8, Batch 500, Loss: -2.9369 (type: 0.423, mdn: -3.360)\n",
      "Epoch 8, Batch 600, Loss: -2.7517 (type: 0.439, mdn: -3.191)\n",
      "Epoch 8, Batch 700, Loss: -2.8243 (type: 0.495, mdn: -3.319)\n",
      "Epoch 8, Batch 800, Loss: -3.4444 (type: 0.382, mdn: -3.826)\n",
      "Epoch 8, Batch 900, Loss: -2.9219 (type: 0.418, mdn: -3.340)\n",
      "Epoch 8, Batch 1000, Loss: -3.0285 (type: 0.421, mdn: -3.449)\n",
      "Epoch 8, Batch 1100, Loss: -3.2217 (type: 0.452, mdn: -3.673)\n",
      "Epoch 8, Batch 1200, Loss: -3.2595 (type: 0.448, mdn: -3.707)\n",
      "Epoch 8, Batch 1300, Loss: -2.8771 (type: 0.442, mdn: -3.319)\n",
      "Epoch 8, Batch 1400, Loss: -3.0939 (type: 0.357, mdn: -3.450)\n",
      "Epoch 8, Batch 1500, Loss: -2.9389 (type: 0.423, mdn: -3.362)\n",
      "Epoch 8, Batch 1600, Loss: -2.9748 (type: 0.353, mdn: -3.328)\n",
      "Epoch 8, Batch 1700, Loss: -2.8370 (type: 0.450, mdn: -3.287)\n",
      "Epoch 8, Batch 1800, Loss: -2.9258 (type: 0.374, mdn: -3.300)\n",
      "Epoch 8, Batch 1900, Loss: -2.9413 (type: 0.382, mdn: -3.324)\n",
      "Epoch 8, Batch 2000, Loss: -2.7645 (type: 0.410, mdn: -3.174)\n",
      "Epoch 8, Batch 2100, Loss: -2.9105 (type: 0.466, mdn: -3.377)\n",
      "Epoch 8, Batch 2200, Loss: -3.1854 (type: 0.474, mdn: -3.659)\n",
      "Epoch 8 avg loss: -3.0026\n",
      "Epoch 9, Batch 0, Loss: -3.3550 (type: 0.397, mdn: -3.752)\n",
      "Epoch 9, Batch 100, Loss: -3.1216 (type: 0.490, mdn: -3.612)\n",
      "Epoch 9, Batch 200, Loss: -3.1405 (type: 0.431, mdn: -3.571)\n",
      "Epoch 9, Batch 300, Loss: -3.1435 (type: 0.399, mdn: -3.543)\n",
      "Epoch 9, Batch 400, Loss: -2.9384 (type: 0.432, mdn: -3.371)\n",
      "Epoch 9, Batch 500, Loss: -3.2151 (type: 0.418, mdn: -3.633)\n",
      "Epoch 9, Batch 600, Loss: -3.0941 (type: 0.513, mdn: -3.607)\n",
      "Epoch 9, Batch 700, Loss: -3.2799 (type: 0.452, mdn: -3.732)\n",
      "Epoch 9, Batch 800, Loss: -2.8430 (type: 0.505, mdn: -3.348)\n",
      "Epoch 9, Batch 900, Loss: -3.3267 (type: 0.575, mdn: -3.902)\n",
      "Epoch 9, Batch 1000, Loss: -2.7480 (type: 0.458, mdn: -3.206)\n",
      "Epoch 9, Batch 1100, Loss: -3.1122 (type: 0.553, mdn: -3.665)\n",
      "Epoch 9, Batch 1200, Loss: -2.7966 (type: 0.418, mdn: -3.215)\n",
      "Epoch 9, Batch 1300, Loss: -3.1746 (type: 0.461, mdn: -3.636)\n",
      "Epoch 9, Batch 1400, Loss: -2.8984 (type: 0.304, mdn: -3.203)\n",
      "Epoch 9, Batch 1500, Loss: -3.1566 (type: 0.401, mdn: -3.558)\n",
      "Epoch 9, Batch 1600, Loss: -2.9478 (type: 0.441, mdn: -3.389)\n",
      "Epoch 9, Batch 1700, Loss: -3.3495 (type: 0.359, mdn: -3.709)\n",
      "Epoch 9, Batch 1800, Loss: -3.0952 (type: 0.473, mdn: -3.568)\n",
      "Epoch 9, Batch 1900, Loss: -3.2533 (type: 0.480, mdn: -3.734)\n",
      "Epoch 9, Batch 2000, Loss: -3.0756 (type: 0.409, mdn: -3.485)\n",
      "Epoch 9, Batch 2100, Loss: -3.2621 (type: 0.454, mdn: -3.716)\n",
      "Epoch 9, Batch 2200, Loss: -2.7204 (type: 0.363, mdn: -3.084)\n",
      "Epoch 9 avg loss: -3.0253\n",
      "Epoch 10, Batch 0, Loss: -3.0072 (type: 0.410, mdn: -3.417)\n",
      "Epoch 10, Batch 100, Loss: -3.3589 (type: 0.367, mdn: -3.726)\n",
      "Epoch 10, Batch 200, Loss: -3.2066 (type: 0.450, mdn: -3.657)\n",
      "Epoch 10, Batch 300, Loss: -3.0990 (type: 0.428, mdn: -3.527)\n",
      "Epoch 10, Batch 400, Loss: -3.4035 (type: 0.399, mdn: -3.803)\n",
      "Epoch 10, Batch 500, Loss: -2.9303 (type: 0.452, mdn: -3.382)\n",
      "Epoch 10, Batch 600, Loss: -2.9874 (type: 0.395, mdn: -3.382)\n",
      "Epoch 10, Batch 700, Loss: -3.1783 (type: 0.452, mdn: -3.630)\n",
      "Epoch 10, Batch 800, Loss: -2.6580 (type: 0.407, mdn: -3.065)\n",
      "Epoch 10, Batch 900, Loss: -3.0335 (type: 0.479, mdn: -3.513)\n",
      "Epoch 10, Batch 1000, Loss: -2.8506 (type: 0.468, mdn: -3.319)\n",
      "Epoch 10, Batch 1100, Loss: -3.3391 (type: 0.475, mdn: -3.814)\n",
      "Epoch 10, Batch 1200, Loss: -3.0112 (type: 0.384, mdn: -3.395)\n",
      "Epoch 10, Batch 1300, Loss: -2.8518 (type: 0.404, mdn: -3.255)\n",
      "Epoch 10, Batch 1400, Loss: -3.2292 (type: 0.367, mdn: -3.596)\n",
      "Epoch 10, Batch 1500, Loss: -2.8796 (type: 0.371, mdn: -3.250)\n",
      "Epoch 10, Batch 1600, Loss: -2.8757 (type: 0.357, mdn: -3.232)\n",
      "Epoch 10, Batch 1700, Loss: -2.7090 (type: 0.399, mdn: -3.108)\n",
      "Epoch 10, Batch 1800, Loss: -3.2090 (type: 0.379, mdn: -3.588)\n",
      "Epoch 10, Batch 1900, Loss: -2.9492 (type: 0.367, mdn: -3.316)\n",
      "Epoch 10, Batch 2000, Loss: -2.6524 (type: 0.387, mdn: -3.039)\n",
      "Epoch 10, Batch 2100, Loss: -2.9808 (type: 0.386, mdn: -3.367)\n",
      "Epoch 10, Batch 2200, Loss: -3.0399 (type: 0.517, mdn: -3.556)\n",
      "Epoch 10 avg loss: -3.0446\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ContinuousXTModel(n_components=5).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward\n",
    "        loss, t_loss, m_loss = combined_loss(model, batch)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f} (type: {t_loss.item():.3f}, mdn: {m_loss.item():.3f})\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} avg loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73bc3c2d-9aa2-46ac-bc2d-cd373aee39e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: -2.9886\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_losses = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, t_loss, m_loss = combined_loss(model, batch)\n",
    "        val_losses.append(loss.item())\n",
    "\n",
    "print(f\"Validation loss: {sum(val_losses)/len(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9200a5bc-eb82-4488-82e7-bd5bd863264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights sum: 1.0\n",
      "Start std range: 0.1000 - 0.1000\n",
      "End std range: 0.0100 - 0.5000\n",
      "\n",
      "Sample component probabilities: tensor([0.2687, 0.0605, 0.0011, 0.0967, 0.5730], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch = next(iter(val_loader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "    \n",
    "    parsed = parse_mdn_params(mdn_params)\n",
    "    \n",
    "    # Sprawdź zakresy\n",
    "    print(f\"Weights sum: {parsed['weights'][0,0].sum()}\")  # powinno być 1.0\n",
    "    print(f\"Start std range: {parsed['start_std'].min():.4f} - {parsed['start_std'].max():.4f}\")\n",
    "    print(f\"End std range: {parsed['end_std'].min():.4f} - {parsed['end_std'].max():.4f}\")\n",
    "    print(f\"\\nSample component probabilities: {parsed['weights'][0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "210377dc-8e84-4a12-8418-ad2d4fe4241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shot: 0.0% (3 samples)\n",
      "GOAL: 100.0% (1 samples)\n",
      "NO_GOAL: 100.0% (31 samples)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_loader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "\n",
    "pred_types = type_logits.argmax(dim=-1)\n",
    "mask = batch['target_types'] != -100\n",
    "\n",
    "for type_id in [1, 2, 3, 4, 5]:\n",
    "    type_mask = (batch['target_types'] == type_id) & mask\n",
    "    if type_mask.sum() > 0:\n",
    "        acc = (pred_types[type_mask] == type_id).float().mean()\n",
    "        print(f\"{id_to_type[type_id]}: {acc:.1%} ({type_mask.sum()} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fe369-1ffd-4d6e-9a84-e9c6cf02767e",
   "metadata": {},
   "source": [
    "### Wyliczanie xT przez Monte Carlo rollouts\n",
    "\n",
    "xT obliczany jako prawdopodobieństwo gola poprzez symulacje kontynuacji akcji:\n",
    "1. Startujemy z początkiem sekwencji (np. pierwsze 3 eventy)\n",
    "2. Generujemy N=100 równoległych rolloutów (max 10 kroków każdy)\n",
    "3. W każdym kroku:\n",
    "   - Sampilujemy typ następnego eventu z rozkładu modelu\n",
    "   - Sampilujemy pozycje z wybranego komponentu MDN\n",
    "   - Kończymy gdy trafiony GOAL lub NO_GOAL\n",
    "4. xT = odsetek rolloutów kończących się GOAL\n",
    "\n",
    "To podejście daje probabilistyczną ocenę zagrożenia uwzględniającą niepewność modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24b30773-41a0-4891-b0e9-6341b5e37b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xT_montecarlo(model, start_sequence, n_rollouts=100, max_steps=10, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Initialize N parallel sequences\n",
    "        seq_types = start_sequence['types'].unsqueeze(0).repeat(n_rollouts, 1)  # [N, T]\n",
    "        seq_positions = start_sequence['positions'].unsqueeze(0).repeat(n_rollouts, 1, 1)\n",
    "        seq_start_mask = start_sequence['start_mask'].unsqueeze(0).repeat(n_rollouts, 1)\n",
    "        \n",
    "        active = torch.ones(n_rollouts, dtype=torch.bool, device=device)  # które wciąż trwają\n",
    "        goals = torch.zeros(n_rollouts, dtype=torch.bool, device=device)  # które skończyły GOAL\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if not active.any():\n",
    "                break\n",
    "            \n",
    "            # Forward pass dla aktywnych\n",
    "            type_logits, mdn_params = model(seq_types, seq_positions, seq_start_mask)\n",
    "            \n",
    "            # Sample types\n",
    "            last_logits = type_logits[:, -1, :]  # [N, vocab_size]\n",
    "            type_probs = F.softmax(last_logits, dim=-1)\n",
    "            next_types = torch.multinomial(type_probs, 1).squeeze(-1)  # [N]\n",
    "            \n",
    "            # Check terminals\n",
    "            is_goal = (next_types == type_vocab['GOAL']) & active\n",
    "            is_no_goal = (next_types == type_vocab['NO_GOAL']) & active\n",
    "            \n",
    "            goals |= is_goal\n",
    "            active &= ~(is_goal | is_no_goal)\n",
    "            \n",
    "            if not active.any():\n",
    "                break\n",
    "            \n",
    "            # Sample positions dla aktywnych Pass/Shot\n",
    "            parsed = parse_mdn_params(mdn_params[:, -1:])  # last timestep\n",
    "            \n",
    "            # Choose components\n",
    "            weights = parsed['weights'][:, 0, :]  # [N, n_components]\n",
    "            k = torch.multinomial(weights, 1).squeeze(-1)  # [N] - wybrany komponent\n",
    "            \n",
    "            # Gather selected component params\n",
    "            batch_idx = torch.arange(n_rollouts, device=device)\n",
    "            start_mean = parsed['start_mean'][batch_idx, 0, k]  # [N, 2]\n",
    "            start_std = parsed['start_std'][batch_idx, 0, k]    # [N]\n",
    "            end_mean = parsed['end_mean'][batch_idx, 0, k]      # [N, 2]\n",
    "            end_std = parsed['end_std'][batch_idx, 0, k]        # [N, 2]\n",
    "            \n",
    "            # Sample positions\n",
    "            start_xy = (start_mean + torch.randn_like(start_mean) * start_std.unsqueeze(-1)).clamp(0, 1)\n",
    "            end_xy = (end_mean + torch.randn_like(end_mean) * end_std).clamp(0, 1)\n",
    "            \n",
    "            # Set end to 0 for Shot\n",
    "            is_shot = (next_types == type_vocab['Shot'])\n",
    "            end_xy[is_shot] = 0.0\n",
    "            \n",
    "            # Append\n",
    "            new_pos = torch.cat([start_xy, end_xy], dim=-1).unsqueeze(1)  # [N, 1, 4]\n",
    "            new_types = next_types.unsqueeze(1)  # [N, 1]\n",
    "            new_mask = torch.ones(n_rollouts, 1, dtype=torch.bool, device=device)\n",
    "            \n",
    "            seq_types = torch.cat([seq_types, new_types], dim=1)\n",
    "            seq_positions = torch.cat([seq_positions, new_pos], dim=1)\n",
    "            seq_start_mask = torch.cat([seq_start_mask, new_mask], dim=1)\n",
    "            \n",
    "            if seq_types.size(1) >= 14:\n",
    "                break\n",
    "    \n",
    "    return goals.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f430e00-22d4-46d8-8c00-83538bac61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_start_sequence(sample, device):\n",
    "    \"\"\"\n",
    "    Przygotuj początkową sekwencję do Monte Carlo\n",
    "    - Seq len 1-2: weź wszystko\n",
    "    - Seq len >2: weź pierwsze 3\n",
    "    \"\"\"\n",
    "    # Znajdź rzeczywistą długość (bez paddingu)\n",
    "    real_len = (sample['input_types'] != type_vocab['<pad>']).sum().item()\n",
    "    \n",
    "    if real_len <= 2:\n",
    "        # Weź wszystko oprócz ostatniego\n",
    "        start_len = real_len\n",
    "    else:\n",
    "        # Weź pierwsze 3\n",
    "        start_len = 3\n",
    "    \n",
    "    return {\n",
    "        'types': sample['input_types'][:start_len].to(device),\n",
    "        'positions': sample['input_positions'][:start_len].to(device),\n",
    "        'start_mask': sample['input_start_mask'][:start_len].to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128cb5ff-dae1-42e4-ab77-983decbe006d",
   "metadata": {},
   "source": [
    "### Ewaluacja modelu\n",
    "\n",
    "Metryki probabilistyczne (właściwe dla xT):\n",
    "- **ROC-AUC**: zdolność rozróżnienia akcji bramkowych vs niebramkowych\n",
    "- **Brier Score**: kalibracja prawdopodobieństw (niższy = lepiej)\n",
    "- **Separacja**: różnica średniego xT dla goli vs nie-goli\n",
    "\n",
    "Każda sekwencja z validation set otrzymuje xT przez 100 rolloutów Monte Carlo. Unikamy accuracy/F1 bo wczesne eventy w akcjach bramkowych *powinny* mieć niskie xT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5a713b8-ac91-4424-94d6-2de23e57d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/51219\n",
      "Processed 200/51219\n",
      "Processed 300/51219\n",
      "Processed 400/51219\n",
      "Processed 500/51219\n",
      "Processed 600/51219\n",
      "Processed 700/51219\n",
      "Processed 800/51219\n",
      "Processed 900/51219\n",
      "Processed 1000/51219\n",
      "Processed 1100/51219\n",
      "Processed 1200/51219\n",
      "Processed 1300/51219\n",
      "Processed 1400/51219\n",
      "Processed 1500/51219\n",
      "Processed 1600/51219\n",
      "Processed 1700/51219\n",
      "Processed 1800/51219\n",
      "Processed 1900/51219\n",
      "Processed 2000/51219\n",
      "Processed 2100/51219\n",
      "Processed 2200/51219\n",
      "Processed 2300/51219\n",
      "Processed 2400/51219\n",
      "Processed 2500/51219\n",
      "Processed 2600/51219\n",
      "Processed 2700/51219\n",
      "Processed 2800/51219\n",
      "Processed 2900/51219\n",
      "Processed 3000/51219\n",
      "Processed 3100/51219\n",
      "Processed 3200/51219\n",
      "Processed 3300/51219\n",
      "Processed 3400/51219\n",
      "Processed 3500/51219\n",
      "Processed 3600/51219\n",
      "Processed 3700/51219\n",
      "Processed 3800/51219\n",
      "Processed 3900/51219\n",
      "Processed 4000/51219\n",
      "Processed 4100/51219\n",
      "Processed 4200/51219\n",
      "Processed 4300/51219\n",
      "Processed 4400/51219\n",
      "Processed 4500/51219\n",
      "Processed 4600/51219\n",
      "Processed 4700/51219\n",
      "Processed 4800/51219\n",
      "Processed 4900/51219\n",
      "Processed 5000/51219\n",
      "Processed 5100/51219\n",
      "Processed 5200/51219\n",
      "Processed 5300/51219\n",
      "Processed 5400/51219\n",
      "Processed 5500/51219\n",
      "Processed 5600/51219\n",
      "Processed 5700/51219\n",
      "Processed 5800/51219\n",
      "Processed 5900/51219\n",
      "Processed 6000/51219\n",
      "Processed 6100/51219\n",
      "Processed 6200/51219\n",
      "Processed 6300/51219\n",
      "Processed 6400/51219\n",
      "Processed 6500/51219\n",
      "Processed 6600/51219\n",
      "Processed 6700/51219\n",
      "Processed 6800/51219\n",
      "Processed 6900/51219\n",
      "Processed 7000/51219\n",
      "Processed 7100/51219\n",
      "Processed 7200/51219\n",
      "Processed 7300/51219\n",
      "Processed 7400/51219\n",
      "Processed 7500/51219\n",
      "Processed 7600/51219\n",
      "Processed 7700/51219\n",
      "Processed 7800/51219\n",
      "Processed 7900/51219\n",
      "Processed 8000/51219\n",
      "Processed 8100/51219\n",
      "Processed 8200/51219\n",
      "Processed 8300/51219\n",
      "Processed 8400/51219\n",
      "Processed 8500/51219\n",
      "Processed 8600/51219\n",
      "Processed 8700/51219\n",
      "Processed 8800/51219\n",
      "Processed 8900/51219\n",
      "Processed 9000/51219\n",
      "Processed 9100/51219\n",
      "Processed 9200/51219\n",
      "Processed 9300/51219\n",
      "Processed 9400/51219\n",
      "Processed 9500/51219\n",
      "Processed 9600/51219\n",
      "Processed 9700/51219\n",
      "Processed 9800/51219\n",
      "Processed 9900/51219\n",
      "Processed 10000/51219\n",
      "Processed 10100/51219\n",
      "Processed 10200/51219\n",
      "Processed 10300/51219\n",
      "Processed 10400/51219\n",
      "Processed 10500/51219\n",
      "Processed 10600/51219\n",
      "Processed 10700/51219\n",
      "Processed 10800/51219\n",
      "Processed 10900/51219\n",
      "Processed 11000/51219\n",
      "Processed 11100/51219\n",
      "Processed 11200/51219\n",
      "Processed 11300/51219\n",
      "Processed 11400/51219\n",
      "Processed 11500/51219\n",
      "Processed 11600/51219\n",
      "Processed 11700/51219\n",
      "Processed 11800/51219\n",
      "Processed 11900/51219\n",
      "Processed 12000/51219\n",
      "Processed 12100/51219\n",
      "Processed 12200/51219\n",
      "Processed 12300/51219\n",
      "Processed 12400/51219\n",
      "Processed 12500/51219\n",
      "Processed 12600/51219\n",
      "Processed 12700/51219\n",
      "Processed 12800/51219\n",
      "Processed 12900/51219\n",
      "Processed 13000/51219\n",
      "Processed 13100/51219\n",
      "Processed 13200/51219\n",
      "Processed 13300/51219\n",
      "Processed 13400/51219\n",
      "Processed 13500/51219\n",
      "Processed 13600/51219\n",
      "Processed 13700/51219\n",
      "Processed 13800/51219\n",
      "Processed 13900/51219\n",
      "Processed 14000/51219\n",
      "Processed 14100/51219\n",
      "Processed 14200/51219\n",
      "Processed 14300/51219\n",
      "Processed 14400/51219\n",
      "Processed 14500/51219\n",
      "Processed 14600/51219\n",
      "Processed 14700/51219\n",
      "Processed 14800/51219\n",
      "Processed 14900/51219\n",
      "Processed 15000/51219\n",
      "Processed 15100/51219\n",
      "Processed 15200/51219\n",
      "Processed 15300/51219\n",
      "Processed 15400/51219\n",
      "Processed 15500/51219\n",
      "Processed 15600/51219\n",
      "Processed 15700/51219\n",
      "Processed 15800/51219\n",
      "Processed 15900/51219\n",
      "Processed 16000/51219\n",
      "Processed 16100/51219\n",
      "Processed 16200/51219\n",
      "Processed 16300/51219\n",
      "Processed 16400/51219\n",
      "Processed 16500/51219\n",
      "Processed 16600/51219\n",
      "Processed 16700/51219\n",
      "Processed 16800/51219\n",
      "Processed 16900/51219\n",
      "Processed 17000/51219\n",
      "Processed 17100/51219\n",
      "Processed 17200/51219\n",
      "Processed 17300/51219\n",
      "Processed 17400/51219\n",
      "Processed 17500/51219\n",
      "Processed 17600/51219\n",
      "Processed 17700/51219\n",
      "Processed 17800/51219\n",
      "Processed 17900/51219\n",
      "Processed 18000/51219\n",
      "Processed 18100/51219\n",
      "Processed 18200/51219\n",
      "Processed 18300/51219\n",
      "Processed 18400/51219\n",
      "Processed 18500/51219\n",
      "Processed 18600/51219\n",
      "Processed 18700/51219\n",
      "Processed 18800/51219\n",
      "Processed 18900/51219\n",
      "Processed 19000/51219\n",
      "Processed 19100/51219\n",
      "Processed 19200/51219\n",
      "Processed 19300/51219\n",
      "Processed 19400/51219\n",
      "Processed 19500/51219\n",
      "Processed 19600/51219\n",
      "Processed 19700/51219\n",
      "Processed 19800/51219\n",
      "Processed 19900/51219\n",
      "Processed 20000/51219\n",
      "Processed 20100/51219\n",
      "Processed 20200/51219\n",
      "Processed 20300/51219\n",
      "Processed 20400/51219\n",
      "Processed 20500/51219\n",
      "Processed 20600/51219\n",
      "Processed 20700/51219\n",
      "Processed 20800/51219\n",
      "Processed 20900/51219\n",
      "Processed 21000/51219\n",
      "Processed 21100/51219\n",
      "Processed 21200/51219\n",
      "Processed 21300/51219\n",
      "Processed 21400/51219\n",
      "Processed 21500/51219\n",
      "Processed 21600/51219\n",
      "Processed 21700/51219\n",
      "Processed 21800/51219\n",
      "Processed 21900/51219\n",
      "Processed 22000/51219\n",
      "Processed 22100/51219\n",
      "Processed 22200/51219\n",
      "Processed 22300/51219\n",
      "Processed 22400/51219\n",
      "Processed 22500/51219\n",
      "Processed 22600/51219\n",
      "Processed 22700/51219\n",
      "Processed 22800/51219\n",
      "Processed 22900/51219\n",
      "Processed 23000/51219\n",
      "Processed 23100/51219\n",
      "Processed 23200/51219\n",
      "Processed 23300/51219\n",
      "Processed 23400/51219\n",
      "Processed 23500/51219\n",
      "Processed 23600/51219\n",
      "Processed 23700/51219\n",
      "Processed 23800/51219\n",
      "Processed 23900/51219\n",
      "Processed 24000/51219\n",
      "Processed 24100/51219\n",
      "Processed 24200/51219\n",
      "Processed 24300/51219\n",
      "Processed 24400/51219\n",
      "Processed 24500/51219\n",
      "Processed 24600/51219\n",
      "Processed 24700/51219\n",
      "Processed 24800/51219\n",
      "Processed 24900/51219\n",
      "Processed 25000/51219\n",
      "Processed 25100/51219\n",
      "Processed 25200/51219\n",
      "Processed 25300/51219\n",
      "Processed 25400/51219\n",
      "Processed 25500/51219\n",
      "Processed 25600/51219\n",
      "Processed 25700/51219\n",
      "Processed 25800/51219\n",
      "Processed 25900/51219\n",
      "Processed 26000/51219\n",
      "Processed 26100/51219\n",
      "Processed 26200/51219\n",
      "Processed 26300/51219\n",
      "Processed 26400/51219\n",
      "Processed 26500/51219\n",
      "Processed 26600/51219\n",
      "Processed 26700/51219\n",
      "Processed 26800/51219\n",
      "Processed 26900/51219\n",
      "Processed 27000/51219\n",
      "Processed 27100/51219\n",
      "Processed 27200/51219\n",
      "Processed 27300/51219\n",
      "Processed 27400/51219\n",
      "Processed 27500/51219\n",
      "Processed 27600/51219\n",
      "Processed 27700/51219\n",
      "Processed 27800/51219\n",
      "Processed 27900/51219\n",
      "Processed 28000/51219\n",
      "Processed 28100/51219\n",
      "Processed 28200/51219\n",
      "Processed 28300/51219\n",
      "Processed 28400/51219\n",
      "Processed 28500/51219\n",
      "Processed 28600/51219\n",
      "Processed 28700/51219\n",
      "Processed 28800/51219\n",
      "Processed 28900/51219\n",
      "Processed 29000/51219\n",
      "Processed 29100/51219\n",
      "Processed 29200/51219\n",
      "Processed 29300/51219\n",
      "Processed 29400/51219\n",
      "Processed 29500/51219\n",
      "Processed 29600/51219\n",
      "Processed 29700/51219\n",
      "Processed 29800/51219\n",
      "Processed 29900/51219\n",
      "Processed 30000/51219\n",
      "Processed 30100/51219\n",
      "Processed 30200/51219\n",
      "Processed 30300/51219\n",
      "Processed 30400/51219\n",
      "Processed 30500/51219\n",
      "Processed 30600/51219\n",
      "Processed 30700/51219\n",
      "Processed 30800/51219\n",
      "Processed 30900/51219\n",
      "Processed 31000/51219\n",
      "Processed 31100/51219\n",
      "Processed 31200/51219\n",
      "Processed 31300/51219\n",
      "Processed 31400/51219\n",
      "Processed 31500/51219\n",
      "Processed 31600/51219\n",
      "Processed 31700/51219\n",
      "Processed 31800/51219\n",
      "Processed 31900/51219\n",
      "Processed 32000/51219\n",
      "Processed 32100/51219\n",
      "Processed 32200/51219\n",
      "Processed 32300/51219\n",
      "Processed 32400/51219\n",
      "Processed 32500/51219\n",
      "Processed 32600/51219\n",
      "Processed 32700/51219\n",
      "Processed 32800/51219\n",
      "Processed 32900/51219\n",
      "Processed 33000/51219\n",
      "Processed 33100/51219\n",
      "Processed 33200/51219\n",
      "Processed 33300/51219\n",
      "Processed 33400/51219\n",
      "Processed 33500/51219\n",
      "Processed 33600/51219\n",
      "Processed 33700/51219\n",
      "Processed 33800/51219\n",
      "Processed 33900/51219\n",
      "Processed 34000/51219\n",
      "Processed 34100/51219\n",
      "Processed 34200/51219\n",
      "Processed 34300/51219\n",
      "Processed 34400/51219\n",
      "Processed 34500/51219\n",
      "Processed 34600/51219\n",
      "Processed 34700/51219\n",
      "Processed 34800/51219\n",
      "Processed 34900/51219\n",
      "Processed 35000/51219\n",
      "Processed 35100/51219\n",
      "Processed 35200/51219\n",
      "Processed 35300/51219\n",
      "Processed 35400/51219\n",
      "Processed 35500/51219\n",
      "Processed 35600/51219\n",
      "Processed 35700/51219\n",
      "Processed 35800/51219\n",
      "Processed 35900/51219\n",
      "Processed 36000/51219\n",
      "Processed 36100/51219\n",
      "Processed 36200/51219\n",
      "Processed 36300/51219\n",
      "Processed 36400/51219\n",
      "Processed 36500/51219\n",
      "Processed 36600/51219\n",
      "Processed 36700/51219\n",
      "Processed 36800/51219\n",
      "Processed 36900/51219\n",
      "Processed 37000/51219\n",
      "Processed 37100/51219\n",
      "Processed 37200/51219\n",
      "Processed 37300/51219\n",
      "Processed 37400/51219\n",
      "Processed 37500/51219\n",
      "Processed 37600/51219\n",
      "Processed 37700/51219\n",
      "Processed 37800/51219\n",
      "Processed 37900/51219\n",
      "Processed 38000/51219\n",
      "Processed 38100/51219\n",
      "Processed 38200/51219\n",
      "Processed 38300/51219\n",
      "Processed 38400/51219\n",
      "Processed 38500/51219\n",
      "Processed 38600/51219\n",
      "Processed 38700/51219\n",
      "Processed 38800/51219\n",
      "Processed 38900/51219\n",
      "Processed 39000/51219\n",
      "Processed 39100/51219\n",
      "Processed 39200/51219\n",
      "Processed 39300/51219\n",
      "Processed 39400/51219\n",
      "Processed 39500/51219\n",
      "Processed 39600/51219\n",
      "Processed 39700/51219\n",
      "Processed 39800/51219\n",
      "Processed 39900/51219\n",
      "Processed 40000/51219\n",
      "Processed 40100/51219\n",
      "Processed 40200/51219\n",
      "Processed 40300/51219\n",
      "Processed 40400/51219\n",
      "Processed 40500/51219\n",
      "Processed 40600/51219\n",
      "Processed 40700/51219\n",
      "Processed 40800/51219\n",
      "Processed 40900/51219\n",
      "Processed 41000/51219\n",
      "Processed 41100/51219\n",
      "Processed 41200/51219\n",
      "Processed 41300/51219\n",
      "Processed 41400/51219\n",
      "Processed 41500/51219\n",
      "Processed 41600/51219\n",
      "Processed 41700/51219\n",
      "Processed 41800/51219\n",
      "Processed 41900/51219\n",
      "Processed 42000/51219\n",
      "Processed 42100/51219\n",
      "Processed 42200/51219\n",
      "Processed 42300/51219\n",
      "Processed 42400/51219\n",
      "Processed 42500/51219\n",
      "Processed 42600/51219\n",
      "Processed 42700/51219\n",
      "Processed 42800/51219\n",
      "Processed 42900/51219\n",
      "Processed 43000/51219\n",
      "Processed 43100/51219\n",
      "Processed 43200/51219\n",
      "Processed 43300/51219\n",
      "Processed 43400/51219\n",
      "Processed 43500/51219\n",
      "Processed 43600/51219\n",
      "Processed 43700/51219\n",
      "Processed 43800/51219\n",
      "Processed 43900/51219\n",
      "Processed 44000/51219\n",
      "Processed 44100/51219\n",
      "Processed 44200/51219\n",
      "Processed 44300/51219\n",
      "Processed 44400/51219\n",
      "Processed 44500/51219\n",
      "Processed 44600/51219\n",
      "Processed 44700/51219\n",
      "Processed 44800/51219\n",
      "Processed 44900/51219\n",
      "Processed 45000/51219\n",
      "Processed 45100/51219\n",
      "Processed 45200/51219\n",
      "Processed 45300/51219\n",
      "Processed 45400/51219\n",
      "Processed 45500/51219\n",
      "Processed 45600/51219\n",
      "Processed 45700/51219\n",
      "Processed 45800/51219\n",
      "Processed 45900/51219\n",
      "Processed 46000/51219\n",
      "Processed 46100/51219\n",
      "Processed 46200/51219\n",
      "Processed 46300/51219\n",
      "Processed 46400/51219\n",
      "Processed 46500/51219\n",
      "Processed 46600/51219\n",
      "Processed 46700/51219\n",
      "Processed 46800/51219\n",
      "Processed 46900/51219\n",
      "Processed 47000/51219\n",
      "Processed 47100/51219\n",
      "Processed 47200/51219\n",
      "Processed 47300/51219\n",
      "Processed 47400/51219\n",
      "Processed 47500/51219\n",
      "Processed 47600/51219\n",
      "Processed 47700/51219\n",
      "Processed 47800/51219\n",
      "Processed 47900/51219\n",
      "Processed 48000/51219\n",
      "Processed 48100/51219\n",
      "Processed 48200/51219\n",
      "Processed 48300/51219\n",
      "Processed 48400/51219\n",
      "Processed 48500/51219\n",
      "Processed 48600/51219\n",
      "Processed 48700/51219\n",
      "Processed 48800/51219\n",
      "Processed 48900/51219\n",
      "Processed 49000/51219\n",
      "Processed 49100/51219\n",
      "Processed 49200/51219\n",
      "Processed 49300/51219\n",
      "Processed 49400/51219\n",
      "Processed 49500/51219\n",
      "Processed 49600/51219\n",
      "Processed 49700/51219\n",
      "Processed 49800/51219\n",
      "Processed 49900/51219\n",
      "Processed 50000/51219\n",
      "Processed 50100/51219\n",
      "Processed 50200/51219\n",
      "Processed 50300/51219\n",
      "Processed 50400/51219\n",
      "Processed 50500/51219\n",
      "Processed 50600/51219\n",
      "Processed 50700/51219\n",
      "Processed 50800/51219\n",
      "Processed 50900/51219\n",
      "Processed 51000/51219\n",
      "Processed 51100/51219\n",
      "Processed 51200/51219\n",
      "\n",
      "ROC-AUC: 0.702\n",
      "Brier Score: 0.013\n",
      "Mean xT (goals): 0.114\n",
      "Mean xT (no goals): 0.010\n"
     ]
    }
   ],
   "source": [
    "val_xTs = []\n",
    "val_labels = []\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    sample = val_dataset[i]\n",
    "    start_seq = prepare_start_sequence(sample, device)\n",
    "    \n",
    "    xT = calculate_xT_montecarlo(model, start_seq, n_rollouts=100)\n",
    "    val_xTs.append(xT)\n",
    "    \n",
    "    # True label (czy akcja skończyła się golem)\n",
    "    label = (sample['target_types'] == type_vocab['GOAL']).any().item()\n",
    "    val_labels.append(label)\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Processed {i+1}/{len(val_dataset)}\")\n",
    "\n",
    "val_xTs = np.array(val_xTs)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "roc_auc = roc_auc_score(val_labels, val_xTs)\n",
    "brier = brier_score_loss(val_labels, val_xTs)\n",
    "\n",
    "print(f\"\\nROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"Brier Score: {brier:.3f}\")\n",
    "print(f\"Mean xT (goals): {val_xTs[val_labels==1].mean():.3f}\")\n",
    "print(f\"Mean xT (no goals): {val_xTs[val_labels==0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34de6b07-04f6-4a50-b467-b19c32288474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input types: tensor([0, 0, 0, 0, 0])\n",
      "Target types: tensor([0, 0, 0, 0, 0])\n",
      "\n",
      "GOAL in input? False\n",
      "GOAL in target? True\n"
     ]
    }
   ],
   "source": [
    "# Weź sekwencję kończącą się GOAL\n",
    "goal_sample = None\n",
    "for i in range(len(val_dataset)):\n",
    "    if (val_dataset[i]['target_types'] == type_vocab['GOAL']).any():\n",
    "        goal_sample = val_dataset[i]\n",
    "        break\n",
    "\n",
    "print(\"Input types:\", goal_sample['input_types'][:5])\n",
    "print(\"Target types:\", goal_sample['target_types'][:5])\n",
    "print(f\"\\nGOAL in input? {(goal_sample['input_types'] == type_vocab['GOAL']).any()}\")\n",
    "print(f\"GOAL in target? {(goal_sample['target_types'] == type_vocab['GOAL']).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cc65329-8a32-4901-b546-20d53fd54a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\barto\\anaconda3\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:177: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/01/17 21:02:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/17 21:02:01 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2026/01/17 21:02:17 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"xT_MDN_Model\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"MDN_Model\"):\n",
    "    # Params\n",
    "    mlflow.log_param(\"model\", \"Transformer_MDN\")\n",
    "    mlflow.log_param(\"epochs\", 10)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"lr\", 1e-4)\n",
    "    mlflow.log_param(\"d_model\", 512)\n",
    "    mlflow.log_param(\"num_layers\", 12)\n",
    "    mlflow.log_param(\"n_components\", 5)\n",
    "    mlflow.log_param(\"loss_weights\", str(WEIGHT_CONFIG))\n",
    "    mlflow.log_param(\"uwagi\", 'top5')\n",
    "\n",
    "    \n",
    "    # Metrics\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"brier_score\", brier)\n",
    "    mlflow.log_metric(\"mean_xT_goals\", val_xTs[val_labels==1].mean())\n",
    "    mlflow.log_metric(\"mean_xT_no_goals\", val_xTs[val_labels==0].mean())\n",
    "    mlflow.log_metric(\"separation\", val_xTs[val_labels==1].mean() - val_xTs[val_labels==0].mean())\n",
    "    \n",
    "    # Model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    \n",
    "    print(\"✅ Logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca660c3-fe92-4a54-bda0-63859fe7b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mdn_heatmap(model, input_seq, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        seq = {k: v.unsqueeze(0).to(device) for k, v in input_seq.items()}\n",
    "        type_logits, mdn_params = model(seq['types'], seq['positions'], seq['start_mask'])\n",
    "        \n",
    "        parsed = parse_mdn_params(mdn_params[:, -1:])\n",
    "        \n",
    "        # Grid\n",
    "        x = np.linspace(0, 1, 120)\n",
    "        y = np.linspace(0, 1, 80)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "        \n",
    "        for k in range(5):\n",
    "            weight = parsed['weights'][0, 0, k].cpu().numpy()\n",
    "            mean = parsed['start_mean'][0, 0, k].cpu().numpy()\n",
    "            std = parsed['start_std'][0, 0, k].cpu().numpy()\n",
    "            Z += weight * np.exp(-((X - mean[0])**2 + (Y - mean[1])**2) / (2 * std**2))\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        im = ax.imshow(Z, origin='lower', extent=[0, 120, 0, 80], cmap='hot', aspect='auto')\n",
    "        ax.set_xlabel('X (m)')\n",
    "        ax.set_ylabel('Y (m)')\n",
    "        ax.set_title('MDN Predicted Start Position Distribution')\n",
    "        plt.colorbar(im, label='Probability Density')\n",
    "        \n",
    "        # Komponenty (niebieskie X)\n",
    "        for k in range(5):\n",
    "            mean = parsed['start_mean'][0, 0, k].cpu().numpy()\n",
    "            ax.scatter(mean[0]*120, mean[1]*80, c='blue', s=100, marker='x', linewidths=3, label='Component' if k==0 else '')\n",
    "        \n",
    "        # AKTUALNA POZYCJA (koniec ostatniego eventu)\n",
    "        last_pos = input_seq['positions'][-1].cpu().numpy()  # [4]: [start_x, start_y, end_x, end_y]\n",
    "        current_x, current_y = last_pos[2], last_pos[3]  # end position\n",
    "        ax.scatter(current_x*120, current_y*80, c='green', s=200, marker='o', edgecolors='black', linewidths=2, label='Current position', zorder=10)\n",
    "        \n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
