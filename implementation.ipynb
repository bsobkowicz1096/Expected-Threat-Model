{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7184e56d-729d-46cb-9669-3dc8325117b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1+cu121\n",
      "CUDA: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# === CELL 1: Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F \n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49048c80-a364-4737-b7e1-da2f4ccf2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: 17,190\n",
      "Goals: 858 (5.0%)\n",
      "Vocab size: 7\n",
      "\n",
      "First sequence:\n",
      "[{'end_x': 0.68, 'end_y': 0.21875, 'type': 'Pass', 'x': 0.955, 'y': 0.43875}\n",
      " {'end_x': 0.54583, 'end_y': 0.39375, 'type': 'Pass', 'x': 0.68, 'y': 0.2225}\n",
      " {'end_x': 0.56667, 'end_y': 0.52375, 'type': 'Pass', 'x': 0.54667, 'y': 0.395}\n",
      " {'end_x': 0.58083, 'end_y': 0.7975, 'type': 'Pass', 'x': 0.57917, 'y': 0.58375}\n",
      " {'end_x': 0.825, 'end_y': 0.93, 'type': 'Pass', 'x': 0.835, 'y': 0.8025}]\n"
     ]
    }
   ],
   "source": [
    "# === CELL 2: Load data ===\n",
    "df = pd.read_parquet('data/sequences_continuous_balanced.parquet')\n",
    "print(f\"Sequences: {len(df):,}\")\n",
    "print(f\"Goals: {df['goal'].sum()} ({df['goal'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Load vocabulary\n",
    "with open('data/vocab_continuous.json', 'r') as f:\n",
    "    type_vocab = json.load(f)\n",
    "\n",
    "with open('data/id_to_type_continuous.json', 'r') as f:\n",
    "    id_to_type = json.load(f)\n",
    "    id_to_type = {int(k): v for k, v in id_to_type.items()}\n",
    "\n",
    "print(f\"Vocab size: {len(type_vocab)}\")\n",
    "print(f\"\\nFirst sequence:\")\n",
    "print(df['events'].iloc[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef3468e-eae4-493e-b6e9-d19a75e6a485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 14,611 | Val: 2,579\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.15, \n",
    "    random_state=42,\n",
    "    stratify=df['goal']  # ważne - zachowaj 5% w obu\n",
    ")\n",
    "print(f\"Train: {len(train_df):,} | Val: {len(val_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13252d18-9b0a-4b0b-9394-7c5ec96e9d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GOAL sequence (last 2 events):\n",
      "[{'end_x': None, 'end_y': None, 'type': 'Shot', 'x': 0.90917, 'y': 0.47625}\n",
      " {'end_x': None, 'end_y': None, 'type': 'GOAL', 'x': None, 'y': None}]\n",
      "\n",
      "NO_GOAL sequence (last event):\n",
      "[{'end_x': 0.46417, 'end_y': 0.52625, 'type': 'Pass', 'x': 0.53333, 'y': 0.23}\n",
      " {'end_x': None, 'end_y': None, 'type': 'NO_GOAL', 'x': None, 'y': None}]\n"
     ]
    }
   ],
   "source": [
    "# Pokaż przykład z GOAL i NO_GOAL\n",
    "goal_seq = df[df['goal'] == 1]['events'].iloc[0]\n",
    "print(f\"\\nGOAL sequence (last 2 events):\")\n",
    "print(goal_seq[-2:])  # powinno być Shot → GOAL\n",
    "\n",
    "no_goal_seq = df[df['goal'] == 0]['events'].iloc[0]\n",
    "print(f\"\\nNO_GOAL sequence (last event):\")\n",
    "print(no_goal_seq[-2:])  # powinno być Shot/Pass → NO_GOAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5133f7b5-63bd-4aba-b6bb-3d00334a8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Shot': 858})\n",
      "Sequence length stats:\n",
      "count    17190.000000\n",
      "mean         5.890867\n",
      "std          3.524482\n",
      "min          2.000000\n",
      "25%          3.000000\n",
      "50%          5.000000\n",
      "75%          8.000000\n",
      "max         13.000000\n",
      "Name: sequence_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Sprawdź czy GOAL zawsze po Shot\n",
    "goal_sequences = df[df['goal'] == 1]['events']\n",
    "\n",
    "shots_before_goal = []\n",
    "for seq in goal_sequences:\n",
    "    if len(seq) >= 2:\n",
    "        shots_before_goal.append(seq[-2]['type'])\n",
    "\n",
    "from collections import Counter\n",
    "print(Counter(shots_before_goal))\n",
    "\n",
    "print(f\"Sequence length stats:\")\n",
    "print(df['sequence_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56dc369b-df04-4eee-a6a4-33cd9379fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousXTDataset(Dataset):\n",
    "    def __init__(self, df, type_vocab, max_seq_len=14):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.type_vocab = type_vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        events = row['events']\n",
    "        \n",
    "        # Causal shift: input predicts next token\n",
    "        input_events = events[:-1]   # [0, 1, 2, ..., n-1]\n",
    "        target_events = events[1:]   # [1, 2, 3, ..., n]\n",
    "        \n",
    "        seq_len = len(input_events)  # rzeczywista długość (bez paddingu)\n",
    "\n",
    "        input_type_ids = [self.type_vocab[e['type']] for e in input_events]\n",
    "        target_type_ids = [self.type_vocab[e['type']] for e in target_events]\n",
    "\n",
    "        # Build position tensors [start_x, start_y, end_x, end_y]\n",
    "        def _build_positions(events_list):\n",
    "            positions = []\n",
    "            for e in events_list:\n",
    "                pos = [\n",
    "                    e['x'] if e['x'] is not None else 0.0,\n",
    "                    e['y'] if e['y'] is not None else 0.0,\n",
    "                    e['end_x'] if e['end_x'] is not None else 0.0,\n",
    "                    e['end_y'] if e['end_y'] is not None else 0.0\n",
    "                ]\n",
    "                positions.append(pos)\n",
    "            return positions\n",
    "\n",
    "        input_positions = _build_positions(input_events)\n",
    "        target_positions = _build_positions(target_events)\n",
    "\n",
    "        # Build masks\n",
    "        def _build_masks(events_list):\n",
    "            start_masks = []\n",
    "            end_masks = []\n",
    "            for e in events_list:\n",
    "                # start_mask: True if event has position (Pass/Shot)\n",
    "                has_start = e['x'] is not None\n",
    "                start_masks.append(has_start)\n",
    "                \n",
    "                # end_mask: True only for Pass (has end_x, end_y)\n",
    "                has_end = e['end_x'] is not None\n",
    "                end_masks.append(has_end)\n",
    "            \n",
    "            return start_masks, end_masks\n",
    "        \n",
    "        input_start_mask, input_end_mask = _build_masks(input_events)\n",
    "        target_start_mask, target_end_mask = _build_masks(target_events)\n",
    "\n",
    "        # Padding\n",
    "        pad_len = self.max_seq_len - seq_len\n",
    "        \n",
    "        # Pad type IDs\n",
    "        input_type_ids += [self.type_vocab['<pad>']] * pad_len\n",
    "        target_type_ids += [-100] * pad_len  # ignore_index for loss\n",
    "        \n",
    "        # Pad positions (zeros)\n",
    "        input_positions += [[0.0, 0.0, 0.0, 0.0]] * pad_len\n",
    "        target_positions += [[0.0, 0.0, 0.0, 0.0]] * pad_len\n",
    "        \n",
    "        # Pad masks (False)\n",
    "        input_start_mask += [False] * pad_len\n",
    "        input_end_mask += [False] * pad_len\n",
    "        target_start_mask += [False] * pad_len\n",
    "        target_end_mask += [False] * pad_len\n",
    "        \n",
    "        # Convert to tensors\n",
    "        return {\n",
    "            'input_types': torch.tensor(input_type_ids, dtype=torch.long),\n",
    "            'input_positions': torch.tensor(input_positions, dtype=torch.float32),\n",
    "            'input_start_mask': torch.tensor(input_start_mask, dtype=torch.bool),\n",
    "            'input_end_mask': torch.tensor(input_end_mask, dtype=torch.bool),\n",
    "            \n",
    "            'target_types': torch.tensor(target_type_ids, dtype=torch.long),\n",
    "            'target_positions': torch.tensor(target_positions, dtype=torch.float32),\n",
    "            'target_start_mask': torch.tensor(target_start_mask, dtype=torch.bool),\n",
    "            'target_end_mask': torch.tensor(target_end_mask, dtype=torch.bool)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "040395bb-b33b-4152-959f-76f842b4873b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 14611\n",
      "Val size: 2579\n",
      "\n",
      "Sample shapes:\n",
      "  input_types: torch.Size([14]) (torch.int64)\n",
      "  input_positions: torch.Size([14, 4]) (torch.float32)\n",
      "  input_start_mask: torch.Size([14]) (torch.bool)\n",
      "  input_end_mask: torch.Size([14]) (torch.bool)\n",
      "  target_types: torch.Size([14]) (torch.int64)\n",
      "  target_positions: torch.Size([14, 4]) (torch.float32)\n",
      "  target_start_mask: torch.Size([14]) (torch.bool)\n",
      "  target_end_mask: torch.Size([14]) (torch.bool)\n",
      "\n",
      "Input types: tensor([1, 1, 6, 6, 6])\n",
      "Target types: tensor([   1,    5, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "# Test dataset\n",
    "train_dataset = ContinuousXTDataset(train_df, type_vocab)\n",
    "val_dataset = ContinuousXTDataset(val_df, type_vocab)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Val size: {len(val_dataset)}\")\n",
    "\n",
    "# Test jednej próbki\n",
    "sample = train_dataset[0]\n",
    "print(f\"\\nSample shapes:\")\n",
    "for k, v in sample.items():\n",
    "    print(f\"  {k}: {v.shape} ({v.dtype})\")\n",
    "\n",
    "print(f\"\\nInput types: {sample['input_types'][:5]}\")\n",
    "print(f\"Target types: {sample['target_types'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8da963c0-fca5-4578-9de2-05392d50295d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch shapes:\n",
      "  input_types: torch.Size([32, 14])\n",
      "  input_positions: torch.Size([32, 14, 4])\n",
      "  input_start_mask: torch.Size([32, 14])\n",
      "  input_end_mask: torch.Size([32, 14])\n",
      "  target_types: torch.Size([32, 14])\n",
      "  target_positions: torch.Size([32, 14, 4])\n",
      "  target_start_mask: torch.Size([32, 14])\n",
      "  target_end_mask: torch.Size([32, 14])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes:\")\n",
    "for k, v in batch.items():\n",
    "    print(f\"  {k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1088820d-3204-4213-903a-4de6c9376dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierPositionEncoder(nn.Module):\n",
    "    def __init__(self, freqs=[1,2,4,8,16,32,64,128], d_model=512):\n",
    "        super().__init__()\n",
    "        self.freqs = torch.tensor(freqs, dtype=torch.float32)\n",
    "        # 4 coords × 8 freqs × 2 (sin/cos) = 64\n",
    "        self.proj = nn.Linear(64, d_model)\n",
    "    \n",
    "    def forward(self, pos):\n",
    "        # pos: [B, T, 4]\n",
    "        B, T, _ = pos.shape\n",
    "        \n",
    "        # Expand: [B,T,4] → [B,T,4,1] × [8] → [B,T,4,8]\n",
    "        freqs = self.freqs.to(pos.device)\n",
    "        pos_expanded = pos.unsqueeze(-1)  # [B,T,4,1]\n",
    "        angles = pos_expanded * freqs  # [B,T,4,8]\n",
    "        \n",
    "        # sin/cos\n",
    "        sin_features = torch.sin(angles)  # [B,T,4,8]\n",
    "        cos_features = torch.cos(angles)  # [B,T,4,8]\n",
    "        \n",
    "        # Flatten: [B,T,4,8,2] → [B,T,64]\n",
    "        fourier = torch.stack([sin_features, cos_features], dim=-1)  # [B,T,4,8,2]\n",
    "        fourier = fourier.reshape(B, T, -1)  # [B,T,64]\n",
    "        \n",
    "        return self.proj(fourier)  # [B,T,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "804d7fdd-914a-410a-837c-3d856d2a5b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "encoder = FourierPositionEncoder()\n",
    "pos = torch.rand(2, 5, 4)  # batch=2, seq=5\n",
    "out = encoder(pos)\n",
    "print(out.shape)  # torch.Size([2, 5, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a222d99-6938-469f-a94e-bdf7fd5f9af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: torch.Size([2, 5, 4])\n",
      "Output: torch.Size([2, 5, 512])\n",
      "Sample values: tensor([ 0.5481, -0.2222,  0.0587, -0.4685,  0.3341], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sample_pos = batch['input_positions'][:2, :5]  # [2, 5, 4]\n",
    "encoded = encoder(sample_pos)\n",
    "print(f\"Input: {sample_pos.shape}\")\n",
    "print(f\"Output: {encoded.shape}\")\n",
    "print(f\"Sample values: {encoded[0,0,:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb115d0c-191f-435f-b024-7c72dd550006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousXTModel(nn.Module):\n",
    "    def __init__(self, vocab_size=7, d_model=512, nhead=8, num_layers=12, n_components=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_components = n_components  # Zapisz jako atrybut\n",
    "        \n",
    "        # Embeddings\n",
    "        self.type_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_encoder = FourierPositionEncoder(d_model=d_model)\n",
    "        \n",
    "        # Transformer\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=2048,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Prediction heads\n",
    "        self.type_head = nn.Linear(d_model, vocab_size)\n",
    "        self.mdn_head = nn.Linear(d_model, n_components * 8)  # n_components × 8\n",
    "    \n",
    "    def forward(self, types, positions, start_mask):\n",
    "        # Embeddings\n",
    "        type_emb = self.type_embedding(types)\n",
    "        pos_emb = self.position_encoder(positions)\n",
    "        \n",
    "        # Mask positions for GOAL/NO_GOAL\n",
    "        pos_emb = pos_emb * start_mask.unsqueeze(-1).float()\n",
    "        combined = type_emb + pos_emb\n",
    "        \n",
    "        # Causal mask\n",
    "        T = types.size(1)\n",
    "        causal_mask = torch.triu(torch.ones(T, T), diagonal=1).bool().to(types.device)\n",
    "        \n",
    "        # Transformer\n",
    "        hidden = self.transformer(combined, mask=causal_mask)\n",
    "        \n",
    "        # Predictions\n",
    "        type_logits = self.type_head(hidden)\n",
    "        mdn_params = self.mdn_head(hidden).view(types.size(0), T, self.n_components, 8)  # [B,T,n_components,8]\n",
    "        \n",
    "        return type_logits, mdn_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b3fc05-9c6d-4163-a9d1-dc9c509554a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type logits: torch.Size([4, 14, 7])\n",
      "MDN params: torch.Size([4, 14, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "model = ContinuousXTModel(n_components=7)\n",
    "type_logits, mdn_params = model(\n",
    "    batch['input_types'][:4],\n",
    "    batch['input_positions'][:4],\n",
    "    batch['input_start_mask'][:4]\n",
    ")\n",
    "print(f\"Type logits: {type_logits.shape}\")\n",
    "print(f\"MDN params: {mdn_params.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1482d734-3508-4555-bd53-b199ca9923ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mdn_params(mdn_params):\n",
    "    \"\"\"\n",
    "    mdn_params: [B, T, 5, 8]\n",
    "    Returns: dict with weights and distributions\n",
    "    \"\"\"\n",
    "    # Extract components\n",
    "    weights = torch.nn.functional.softmax(mdn_params[..., 0], dim=-1)  # [B,T,5] - sum to 1\n",
    "    \n",
    "    # Start position (μ, σ)\n",
    "    start_mean_x = torch.sigmoid(mdn_params[..., 1])  # [B,T,5] in [0,1]\n",
    "    start_mean_y = torch.sigmoid(mdn_params[..., 2])\n",
    "    start_std = torch.exp(mdn_params[..., 3]).clamp(0.005, 0.1)  # small variance\n",
    "    \n",
    "    # End position (μx, μy, σx, σy)\n",
    "    end_mean_x = torch.sigmoid(mdn_params[..., 4])\n",
    "    end_mean_y = torch.sigmoid(mdn_params[..., 5])\n",
    "    end_std_x = torch.exp(mdn_params[..., 6]).clamp(0.01, 0.5)  # wider variance\n",
    "    end_std_y = torch.exp(mdn_params[..., 7]).clamp(0.01, 0.5)\n",
    "    \n",
    "    return {\n",
    "        'weights': weights,\n",
    "        'start_mean': torch.stack([start_mean_x, start_mean_y], dim=-1),  # [B,T,5,2]\n",
    "        'start_std': start_std,  # [B,T,5]\n",
    "        'end_mean': torch.stack([end_mean_x, end_mean_y], dim=-1),  # [B,T,5,2]\n",
    "        'end_std': torch.stack([end_std_x, end_std_y], dim=-1)  # [B,T,5,2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d641403f-f649-4a09-a9f8-c105888fb1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: torch.Size([4, 14, 7])\n",
      "start_mean: torch.Size([4, 14, 7, 2])\n",
      "start_std: torch.Size([4, 14, 7])\n",
      "end_mean: torch.Size([4, 14, 7, 2])\n",
      "end_std: torch.Size([4, 14, 7, 2])\n"
     ]
    }
   ],
   "source": [
    "parsed = parse_mdn_params(mdn_params)\n",
    "for k, v in parsed.items():\n",
    "    print(f\"{k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c340b203-dd5f-4b76-a891-9d50a960a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_CONFIG = {\n",
    "    \"START\": 1.0,\n",
    "    \"Pass\": 1.0,\n",
    "    \"Carry\": 5.0,\n",
    "    \"Shot\": 10.0,\n",
    "    \"GOAL\": 30.0,\n",
    "    \"NO_GOAL\": 1.0,\n",
    "    \"<pad>\": 1.0\n",
    "}\n",
    "\n",
    "def type_loss(type_logits, target_types):\n",
    "    # Wagi z config\n",
    "    weights = torch.tensor([\n",
    "        WEIGHT_CONFIG[\"START\"],\n",
    "        WEIGHT_CONFIG[\"Pass\"],\n",
    "        WEIGHT_CONFIG[\"Carry\"],\n",
    "        WEIGHT_CONFIG[\"Shot\"],\n",
    "        WEIGHT_CONFIG[\"GOAL\"],\n",
    "        WEIGHT_CONFIG[\"NO_GOAL\"],\n",
    "        WEIGHT_CONFIG[\"<pad>\"]\n",
    "    ]).to(type_logits.device)\n",
    "    \n",
    "    return F.cross_entropy(\n",
    "        type_logits.reshape(-1, 7),\n",
    "        target_types.reshape(-1),\n",
    "        weight=weights,\n",
    "        ignore_index=-100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "870bd3a8-816a-417c-8186-2596161723f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_nll(target, mean, std):\n",
    "    \"\"\"Negative log-likelihood of Gaussian\"\"\"\n",
    "    variance = std ** 2\n",
    "    return 0.5 * (torch.log(2 * torch.pi * variance) + ((target - mean) ** 2) / variance)\n",
    "\n",
    "def mdn_loss(mdn_params, target_positions, target_start_mask, target_end_mask):\n",
    "    \"\"\"\n",
    "    mdn_params: [B, T, n_components, 8]\n",
    "    target_positions: [B, T, 4] - [start_x, start_y, end_x, end_y]\n",
    "    \"\"\"\n",
    "    parsed = parse_mdn_params(mdn_params)\n",
    "    B, T, n_components = mdn_params.shape[:3]  # Dynamicznie pobierz n_components\n",
    "    \n",
    "    # Target positions\n",
    "    target_start = target_positions[..., :2]  # [B,T,2]\n",
    "    target_end = target_positions[..., 2:]    # [B,T,2]\n",
    "    \n",
    "    # Compute NLL for each component\n",
    "    component_nll = []\n",
    "    for k in range(n_components):  # 5 → n_components\n",
    "        # Start NLL\n",
    "        start_nll = gaussian_nll(\n",
    "            target_start.unsqueeze(2),\n",
    "            parsed['start_mean'][:, :, k:k+1, :],\n",
    "            parsed['start_std'][:, :, k:k+1].unsqueeze(-1)\n",
    "        ).sum(dim=-1)\n",
    "        \n",
    "        # End NLL\n",
    "        end_nll = gaussian_nll(\n",
    "            target_end.unsqueeze(2),\n",
    "            parsed['end_mean'][:, :, k:k+1, :],\n",
    "            parsed['end_std'][:, :, k:k+1, :]\n",
    "        ).sum(dim=-1)\n",
    "        \n",
    "        component_nll.append(start_nll + end_nll)\n",
    "    \n",
    "    component_nll = torch.cat(component_nll, dim=-1)  # [B,T,n_components]\n",
    "    \n",
    "    # Mixture NLL\n",
    "    log_weights = torch.log(parsed['weights'] + 1e-8)\n",
    "    mixture_nll = -torch.logsumexp(log_weights - component_nll, dim=-1)\n",
    "    \n",
    "    # Mask\n",
    "    mask = target_start_mask.float()\n",
    "    return (mixture_nll * mask).sum() / mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1160126-5fad-41f3-b9f7-d4628d16fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type loss: 1.8513\n",
      "MDN loss: 1.9631\n"
     ]
    }
   ],
   "source": [
    "type_l = type_loss(type_logits, batch['target_types'][:4])\n",
    "mdn_l = mdn_loss(mdn_params, batch['target_positions'][:4], \n",
    "                 batch['target_start_mask'][:4], batch['target_end_mask'][:4])\n",
    "print(f\"Type loss: {type_l.item():.4f}\")\n",
    "print(f\"MDN loss: {mdn_l.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30489260-0b7a-46ea-8357-981673d7b231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined loss\n",
    "def combined_loss(model, batch):\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "    \n",
    "    t_loss = type_loss(type_logits, batch['target_types'])\n",
    "    m_loss = mdn_loss(\n",
    "        mdn_params, \n",
    "        batch['target_positions'],\n",
    "        batch['target_start_mask'],\n",
    "        batch['target_end_mask']\n",
    "    )\n",
    "    \n",
    "    return t_loss + m_loss, t_loss, m_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12ac2ca2-8634-4e9a-8c8a-91a02e61b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 0, Loss: 5.0475 (type: 2.060, mdn: 2.987)\n",
      "Epoch 1, Batch 100, Loss: 0.1880 (type: 0.590, mdn: -0.402)\n",
      "Epoch 1, Batch 200, Loss: -1.2074 (type: 0.761, mdn: -1.969)\n",
      "Epoch 1, Batch 300, Loss: -2.2303 (type: 0.640, mdn: -2.870)\n",
      "Epoch 1, Batch 400, Loss: -2.5320 (type: 0.512, mdn: -3.044)\n",
      "Epoch 1 avg loss: -0.9306\n",
      "Epoch 2, Batch 0, Loss: -2.2857 (type: 0.642, mdn: -2.927)\n",
      "Epoch 2, Batch 100, Loss: -2.3303 (type: 0.622, mdn: -2.952)\n",
      "Epoch 2, Batch 200, Loss: -2.5106 (type: 0.589, mdn: -3.100)\n",
      "Epoch 2, Batch 300, Loss: -1.9779 (type: 0.937, mdn: -2.915)\n",
      "Epoch 2, Batch 400, Loss: -2.1561 (type: 0.525, mdn: -2.681)\n",
      "Epoch 2 avg loss: -2.3955\n",
      "Epoch 3, Batch 0, Loss: -2.7831 (type: 0.509, mdn: -3.292)\n",
      "Epoch 3, Batch 100, Loss: -2.2495 (type: 0.669, mdn: -2.919)\n",
      "Epoch 3, Batch 200, Loss: -2.3548 (type: 0.676, mdn: -3.031)\n",
      "Epoch 3, Batch 300, Loss: -2.4380 (type: 0.743, mdn: -3.181)\n",
      "Epoch 3, Batch 400, Loss: -2.6564 (type: 0.564, mdn: -3.221)\n",
      "Epoch 3 avg loss: -2.5146\n",
      "Epoch 4, Batch 0, Loss: -2.6582 (type: 0.618, mdn: -3.276)\n",
      "Epoch 4, Batch 100, Loss: -2.2316 (type: 0.627, mdn: -2.859)\n",
      "Epoch 4, Batch 200, Loss: -2.3060 (type: 0.766, mdn: -3.072)\n",
      "Epoch 4, Batch 300, Loss: -2.9016 (type: 0.682, mdn: -3.584)\n",
      "Epoch 4, Batch 400, Loss: -2.5261 (type: 0.656, mdn: -3.182)\n",
      "Epoch 4 avg loss: -2.5822\n",
      "Epoch 5, Batch 0, Loss: -2.6870 (type: 0.419, mdn: -3.106)\n",
      "Epoch 5, Batch 100, Loss: -2.5779 (type: 0.595, mdn: -3.173)\n",
      "Epoch 5, Batch 200, Loss: -2.2927 (type: 0.735, mdn: -3.028)\n",
      "Epoch 5, Batch 300, Loss: -2.2896 (type: 0.671, mdn: -2.961)\n",
      "Epoch 5, Batch 400, Loss: -2.9291 (type: 0.475, mdn: -3.404)\n",
      "Epoch 5 avg loss: -2.6214\n",
      "Epoch 6, Batch 0, Loss: -2.4605 (type: 0.473, mdn: -2.934)\n",
      "Epoch 6, Batch 100, Loss: -2.2246 (type: 0.772, mdn: -2.997)\n",
      "Epoch 6, Batch 200, Loss: -2.7582 (type: 0.494, mdn: -3.252)\n",
      "Epoch 6, Batch 300, Loss: -2.8197 (type: 0.469, mdn: -3.289)\n",
      "Epoch 6, Batch 400, Loss: -2.6155 (type: 0.689, mdn: -3.304)\n",
      "Epoch 6 avg loss: -2.6608\n",
      "Epoch 7, Batch 0, Loss: -2.6740 (type: 0.571, mdn: -3.245)\n",
      "Epoch 7, Batch 100, Loss: -2.0968 (type: 0.789, mdn: -2.886)\n",
      "Epoch 7, Batch 200, Loss: -2.9439 (type: 0.467, mdn: -3.411)\n",
      "Epoch 7, Batch 300, Loss: -2.7155 (type: 0.680, mdn: -3.395)\n",
      "Epoch 7, Batch 400, Loss: -2.5769 (type: 0.442, mdn: -3.019)\n",
      "Epoch 7 avg loss: -2.6962\n",
      "Epoch 8, Batch 0, Loss: -2.6073 (type: 0.421, mdn: -3.028)\n",
      "Epoch 8, Batch 100, Loss: -3.0080 (type: 0.458, mdn: -3.466)\n",
      "Epoch 8, Batch 200, Loss: -2.7387 (type: 0.683, mdn: -3.421)\n",
      "Epoch 8, Batch 300, Loss: -2.1697 (type: 0.631, mdn: -2.801)\n",
      "Epoch 8, Batch 400, Loss: -2.5529 (type: 0.550, mdn: -3.103)\n",
      "Epoch 8 avg loss: -2.7230\n",
      "Epoch 9, Batch 0, Loss: -3.1618 (type: 0.437, mdn: -3.599)\n",
      "Epoch 9, Batch 100, Loss: -2.8841 (type: 0.474, mdn: -3.359)\n",
      "Epoch 9, Batch 200, Loss: -2.5072 (type: 0.429, mdn: -2.937)\n",
      "Epoch 9, Batch 300, Loss: -2.7120 (type: 0.592, mdn: -3.304)\n",
      "Epoch 9, Batch 400, Loss: -2.7976 (type: 0.548, mdn: -3.346)\n",
      "Epoch 9 avg loss: -2.7620\n",
      "Epoch 10, Batch 0, Loss: -2.5582 (type: 0.654, mdn: -3.213)\n",
      "Epoch 10, Batch 100, Loss: -2.8604 (type: 0.471, mdn: -3.331)\n",
      "Epoch 10, Batch 200, Loss: -2.6393 (type: 0.629, mdn: -3.268)\n",
      "Epoch 10, Batch 300, Loss: -2.7844 (type: 0.445, mdn: -3.229)\n",
      "Epoch 10, Batch 400, Loss: -2.4679 (type: 0.753, mdn: -3.221)\n",
      "Epoch 10 avg loss: -2.7785\n",
      "Epoch 11, Batch 0, Loss: -2.9860 (type: 0.536, mdn: -3.522)\n",
      "Epoch 11, Batch 100, Loss: -2.9062 (type: 0.626, mdn: -3.533)\n",
      "Epoch 11, Batch 200, Loss: -2.5591 (type: 0.633, mdn: -3.192)\n",
      "Epoch 11, Batch 300, Loss: -2.9063 (type: 0.610, mdn: -3.516)\n",
      "Epoch 11, Batch 400, Loss: -2.4022 (type: 0.721, mdn: -3.123)\n",
      "Epoch 11 avg loss: -2.8217\n",
      "Epoch 12, Batch 0, Loss: -3.0082 (type: 0.401, mdn: -3.409)\n",
      "Epoch 12, Batch 100, Loss: -2.9932 (type: 0.367, mdn: -3.361)\n",
      "Epoch 12, Batch 200, Loss: -2.7780 (type: 0.559, mdn: -3.337)\n",
      "Epoch 12, Batch 300, Loss: -2.4822 (type: 0.394, mdn: -2.876)\n",
      "Epoch 12, Batch 400, Loss: -3.3474 (type: 0.345, mdn: -3.693)\n",
      "Epoch 12 avg loss: -2.8470\n",
      "Epoch 13, Batch 0, Loss: -3.0317 (type: 0.499, mdn: -3.530)\n",
      "Epoch 13, Batch 100, Loss: -3.0855 (type: 0.405, mdn: -3.491)\n",
      "Epoch 13, Batch 200, Loss: -2.5389 (type: 0.714, mdn: -3.253)\n",
      "Epoch 13, Batch 300, Loss: -2.7260 (type: 0.706, mdn: -3.432)\n",
      "Epoch 13, Batch 400, Loss: -2.9009 (type: 0.695, mdn: -3.596)\n",
      "Epoch 13 avg loss: -2.8930\n",
      "Epoch 14, Batch 0, Loss: -3.0633 (type: 0.519, mdn: -3.582)\n",
      "Epoch 14, Batch 100, Loss: -3.0352 (type: 0.452, mdn: -3.487)\n",
      "Epoch 14, Batch 200, Loss: -3.1253 (type: 0.425, mdn: -3.550)\n",
      "Epoch 14, Batch 300, Loss: -3.1239 (type: 0.486, mdn: -3.609)\n",
      "Epoch 14, Batch 400, Loss: -2.9478 (type: 0.478, mdn: -3.426)\n",
      "Epoch 14 avg loss: -2.9305\n",
      "Epoch 15, Batch 0, Loss: -2.8357 (type: 0.462, mdn: -3.298)\n",
      "Epoch 15, Batch 100, Loss: -2.8681 (type: 0.478, mdn: -3.346)\n",
      "Epoch 15, Batch 200, Loss: -2.9428 (type: 0.455, mdn: -3.398)\n",
      "Epoch 15, Batch 300, Loss: -2.7750 (type: 0.579, mdn: -3.354)\n",
      "Epoch 15, Batch 400, Loss: -3.1706 (type: 0.318, mdn: -3.489)\n",
      "Epoch 15 avg loss: -2.9813\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ContinuousXTModel(n_components=5).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "\n",
    "epochs = 15  # start small\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward\n",
    "        loss, t_loss, m_loss = combined_loss(model, batch)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f} (type: {t_loss.item():.3f}, mdn: {m_loss.item():.3f})\")\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} avg loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73bc3c2d-9aa2-46ac-bc2d-cd373aee39e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: -2.6947\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_losses = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        loss, t_loss, m_loss = combined_loss(model, batch)\n",
    "        val_losses.append(loss.item())\n",
    "\n",
    "print(f\"Validation loss: {sum(val_losses)/len(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9200a5bc-eb82-4488-82e7-bd5bd863264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights sum: 1.0\n",
      "Start std range: 0.1000 - 0.1000\n",
      "End std range: 0.0100 - 0.5000\n",
      "\n",
      "Sample component probabilities: tensor([0.2164, 0.5670, 0.0046, 0.2035, 0.0086], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "batch = next(iter(val_loader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "    \n",
    "    parsed = parse_mdn_params(mdn_params)\n",
    "    \n",
    "    # Sprawdź zakresy\n",
    "    print(f\"Weights sum: {parsed['weights'][0,0].sum()}\")  # powinno być 1.0\n",
    "    print(f\"Start std range: {parsed['start_std'].min():.4f} - {parsed['start_std'].max():.4f}\")\n",
    "    print(f\"End std range: {parsed['end_std'].min():.4f} - {parsed['end_std'].max():.4f}\")\n",
    "    print(f\"\\nSample component probabilities: {parsed['weights'][0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45a02b98-1477-4e1a-8d99-0899dc5dfac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 54568, 5: 13882, 3: 2371, 4: 729})\n"
     ]
    }
   ],
   "source": [
    "train_targets = []\n",
    "for batch in train_loader:\n",
    "    train_targets.extend(batch['target_types'][batch['target_types'] != -100].tolist())\n",
    "print(Counter(train_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "210377dc-8e84-4a12-8418-ad2d4fe4241c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass: 95.5% (154 samples)\n",
      "Shot: 40.0% (5 samples)\n",
      "GOAL: 100.0% (3 samples)\n",
      "NO_GOAL: 13.8% (29 samples)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_loader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    type_logits, mdn_params = model(\n",
    "        batch['input_types'],\n",
    "        batch['input_positions'],\n",
    "        batch['input_start_mask']\n",
    "    )\n",
    "\n",
    "pred_types = type_logits.argmax(dim=-1)\n",
    "mask = batch['target_types'] != -100\n",
    "\n",
    "for type_id in [1, 3, 4, 5]:\n",
    "    type_mask = (batch['target_types'] == type_id) & mask\n",
    "    if type_mask.sum() > 0:\n",
    "        acc = (pred_types[type_mask] == type_id).float().mean()\n",
    "        print(f\"{id_to_type[type_id]}: {acc:.1%} ({type_mask.sum()} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24b30773-41a0-4891-b0e9-6341b5e37b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xT_montecarlo(model, start_sequence, n_rollouts=100, max_steps=10, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Initialize N parallel sequences\n",
    "        seq_types = start_sequence['types'].unsqueeze(0).repeat(n_rollouts, 1)  # [N, T]\n",
    "        seq_positions = start_sequence['positions'].unsqueeze(0).repeat(n_rollouts, 1, 1)\n",
    "        seq_start_mask = start_sequence['start_mask'].unsqueeze(0).repeat(n_rollouts, 1)\n",
    "        \n",
    "        active = torch.ones(n_rollouts, dtype=torch.bool, device=device)  # które wciąż trwają\n",
    "        goals = torch.zeros(n_rollouts, dtype=torch.bool, device=device)  # które skończyły GOAL\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            if not active.any():\n",
    "                break\n",
    "            \n",
    "            # Forward pass dla aktywnych\n",
    "            type_logits, mdn_params = model(seq_types, seq_positions, seq_start_mask)\n",
    "            \n",
    "            # Sample types\n",
    "            last_logits = type_logits[:, -1, :]  # [N, vocab_size]\n",
    "            type_probs = F.softmax(last_logits, dim=-1)\n",
    "            next_types = torch.multinomial(type_probs, 1).squeeze(-1)  # [N]\n",
    "            \n",
    "            # Check terminals\n",
    "            is_goal = (next_types == type_vocab['GOAL']) & active\n",
    "            is_no_goal = (next_types == type_vocab['NO_GOAL']) & active\n",
    "            \n",
    "            goals |= is_goal\n",
    "            active &= ~(is_goal | is_no_goal)\n",
    "            \n",
    "            if not active.any():\n",
    "                break\n",
    "            \n",
    "            # Sample positions dla aktywnych Pass/Shot\n",
    "            parsed = parse_mdn_params(mdn_params[:, -1:])  # last timestep\n",
    "            \n",
    "            # Choose components\n",
    "            weights = parsed['weights'][:, 0, :]  # [N, n_components]\n",
    "            k = torch.multinomial(weights, 1).squeeze(-1)  # [N] - wybrany komponent\n",
    "            \n",
    "            # Gather selected component params\n",
    "            batch_idx = torch.arange(n_rollouts, device=device)\n",
    "            start_mean = parsed['start_mean'][batch_idx, 0, k]  # [N, 2]\n",
    "            start_std = parsed['start_std'][batch_idx, 0, k]    # [N]\n",
    "            end_mean = parsed['end_mean'][batch_idx, 0, k]      # [N, 2]\n",
    "            end_std = parsed['end_std'][batch_idx, 0, k]        # [N, 2]\n",
    "            \n",
    "            # Sample positions\n",
    "            start_xy = (start_mean + torch.randn_like(start_mean) * start_std.unsqueeze(-1)).clamp(0, 1)\n",
    "            end_xy = (end_mean + torch.randn_like(end_mean) * end_std).clamp(0, 1)\n",
    "            \n",
    "            # Set end to 0 for Shot\n",
    "            is_shot = (next_types == type_vocab['Shot'])\n",
    "            end_xy[is_shot] = 0.0\n",
    "            \n",
    "            # Append\n",
    "            new_pos = torch.cat([start_xy, end_xy], dim=-1).unsqueeze(1)  # [N, 1, 4]\n",
    "            new_types = next_types.unsqueeze(1)  # [N, 1]\n",
    "            new_mask = torch.ones(n_rollouts, 1, dtype=torch.bool, device=device)\n",
    "            \n",
    "            seq_types = torch.cat([seq_types, new_types], dim=1)\n",
    "            seq_positions = torch.cat([seq_positions, new_pos], dim=1)\n",
    "            seq_start_mask = torch.cat([seq_start_mask, new_mask], dim=1)\n",
    "            \n",
    "            if seq_types.size(1) >= 14:\n",
    "                break\n",
    "    \n",
    "    return goals.float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f430e00-22d4-46d8-8c00-83538bac61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_start_sequence(sample, device):\n",
    "    \"\"\"\n",
    "    Przygotuj początkową sekwencję do Monte Carlo\n",
    "    - Seq len 1-2: weź wszystko\n",
    "    - Seq len >2: weź pierwsze 3\n",
    "    \"\"\"\n",
    "    # Znajdź rzeczywistą długość (bez paddingu)\n",
    "    real_len = (sample['input_types'] != type_vocab['<pad>']).sum().item()\n",
    "    \n",
    "    if real_len <= 2:\n",
    "        # Weź wszystko oprócz ostatniego\n",
    "        start_len = real_len\n",
    "    else:\n",
    "        # Weź pierwsze 3\n",
    "        start_len = 3\n",
    "    \n",
    "    return {\n",
    "        'types': sample['input_types'][:start_len].to(device),\n",
    "        'positions': sample['input_positions'][:start_len].to(device),\n",
    "        'start_mask': sample['input_start_mask'][:start_len].to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5a713b8-ac91-4424-94d6-2de23e57d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100/2579\n",
      "Processed 200/2579\n",
      "Processed 300/2579\n",
      "Processed 400/2579\n",
      "Processed 500/2579\n",
      "Processed 600/2579\n",
      "Processed 700/2579\n",
      "Processed 800/2579\n",
      "Processed 900/2579\n",
      "Processed 1000/2579\n",
      "Processed 1100/2579\n",
      "Processed 1200/2579\n",
      "Processed 1300/2579\n",
      "Processed 1400/2579\n",
      "Processed 1500/2579\n",
      "Processed 1600/2579\n",
      "Processed 1700/2579\n",
      "Processed 1800/2579\n",
      "Processed 1900/2579\n",
      "Processed 2000/2579\n",
      "Processed 2100/2579\n",
      "Processed 2200/2579\n",
      "Processed 2300/2579\n",
      "Processed 2400/2579\n",
      "Processed 2500/2579\n",
      "\n",
      "ROC-AUC: 0.702\n",
      "Brier Score: 0.156\n",
      "Mean xT (goals): 0.535\n",
      "Mean xT (no goals): 0.306\n"
     ]
    }
   ],
   "source": [
    "val_xTs = []\n",
    "val_labels = []\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "    sample = val_dataset[i]\n",
    "    start_seq = prepare_start_sequence(sample, device)\n",
    "    \n",
    "    xT = calculate_xT_montecarlo(model, start_seq, n_rollouts=100)\n",
    "    val_xTs.append(xT)\n",
    "    \n",
    "    # True label (czy akcja skończyła się golem)\n",
    "    label = (sample['target_types'] == type_vocab['GOAL']).any().item()\n",
    "    val_labels.append(label)\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print(f\"Processed {i+1}/{len(val_dataset)}\")\n",
    "\n",
    "val_xTs = np.array(val_xTs)\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "\n",
    "roc_auc = roc_auc_score(val_labels, val_xTs)\n",
    "brier = brier_score_loss(val_labels, val_xTs)\n",
    "\n",
    "print(f\"\\nROC-AUC: {roc_auc:.3f}\")\n",
    "print(f\"Brier Score: {brier:.3f}\")\n",
    "print(f\"Mean xT (goals): {val_xTs[val_labels==1].mean():.3f}\")\n",
    "print(f\"Mean xT (no goals): {val_xTs[val_labels==0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34de6b07-04f6-4a50-b467-b19c32288474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input types: tensor([1, 3, 3, 6, 6])\n",
      "Target types: tensor([   3,    3,    4, -100, -100])\n",
      "\n",
      "GOAL in input? False\n",
      "GOAL in target? True\n"
     ]
    }
   ],
   "source": [
    "# Weź sekwencję kończącą się GOAL\n",
    "goal_sample = None\n",
    "for i in range(len(val_dataset)):\n",
    "    if (val_dataset[i]['target_types'] == type_vocab['GOAL']).any():\n",
    "        goal_sample = val_dataset[i]\n",
    "        break\n",
    "\n",
    "print(\"Input types:\", goal_sample['input_types'][:5])\n",
    "print(\"Target types:\", goal_sample['target_types'][:5])\n",
    "print(f\"\\nGOAL in input? {(goal_sample['input_types'] == type_vocab['GOAL']).any()}\")\n",
    "print(f\"GOAL in target? {(goal_sample['target_types'] == type_vocab['GOAL']).any()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cc65329-8a32-4901-b546-20d53fd54a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/30 11:44:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/30 11:44:13 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/11/30 11:44:24 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/11/30 11:44:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"xT_Model\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"MDN_Model\"):\n",
    "    # Params\n",
    "    mlflow.log_param(\"model\", \"Transformer_MDN\")\n",
    "    mlflow.log_param(\"epochs\", 15)\n",
    "    mlflow.log_param(\"batch_size\", 32)\n",
    "    mlflow.log_param(\"lr\", 1e-4)\n",
    "    mlflow.log_param(\"d_model\", 512)\n",
    "    mlflow.log_param(\"num_layers\", 12)\n",
    "    mlflow.log_param(\"n_components\", 5)\n",
    "    mlflow.log_param(\"loss_weights\", str(WEIGHT_CONFIG))\n",
    "    mlflow.log_param(\"uwagi\", '')\n",
    "\n",
    "    \n",
    "    # Metrics\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"brier_score\", brier)\n",
    "    mlflow.log_metric(\"mean_xT_goals\", val_xTs[val_labels==1].mean())\n",
    "    mlflow.log_metric(\"mean_xT_no_goals\", val_xTs[val_labels==0].mean())\n",
    "    mlflow.log_metric(\"separation\", val_xTs[val_labels==1].mean() - val_xTs[val_labels==0].mean())\n",
    "    \n",
    "    # Model\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    \n",
    "    print(\"✅ Logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ca660c3-fe92-4a54-bda0-63859fe7b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mdn_heatmap(model, input_seq, device='cuda'):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        seq = {k: v.unsqueeze(0).to(device) for k, v in input_seq.items()}\n",
    "        type_logits, mdn_params = model(seq['types'], seq['positions'], seq['start_mask'])\n",
    "        \n",
    "        parsed = parse_mdn_params(mdn_params[:, -1:])\n",
    "        \n",
    "        # Grid\n",
    "        x = np.linspace(0, 1, 120)\n",
    "        y = np.linspace(0, 1, 80)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = np.zeros_like(X)\n",
    "        \n",
    "        for k in range(5):\n",
    "            weight = parsed['weights'][0, 0, k].cpu().numpy()\n",
    "            mean = parsed['start_mean'][0, 0, k].cpu().numpy()\n",
    "            std = parsed['start_std'][0, 0, k].cpu().numpy()\n",
    "            Z += weight * np.exp(-((X - mean[0])**2 + (Y - mean[1])**2) / (2 * std**2))\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        im = ax.imshow(Z, origin='lower', extent=[0, 120, 0, 80], cmap='hot', aspect='auto')\n",
    "        ax.set_xlabel('X (m)')\n",
    "        ax.set_ylabel('Y (m)')\n",
    "        ax.set_title('MDN Predicted Start Position Distribution')\n",
    "        plt.colorbar(im, label='Probability Density')\n",
    "        \n",
    "        # Komponenty (niebieskie X)\n",
    "        for k in range(5):\n",
    "            mean = parsed['start_mean'][0, 0, k].cpu().numpy()\n",
    "            ax.scatter(mean[0]*120, mean[1]*80, c='blue', s=100, marker='x', linewidths=3, label='Component' if k==0 else '')\n",
    "        \n",
    "        # AKTUALNA POZYCJA (koniec ostatniego eventu)\n",
    "        last_pos = input_seq['positions'][-1].cpu().numpy()  # [4]: [start_x, start_y, end_x, end_y]\n",
    "        current_x, current_y = last_pos[2], last_pos[3]  # end position\n",
    "        ax.scatter(current_x*120, current_y*80, c='green', s=200, marker='o', edgecolors='black', linewidths=2, label='Current position', zorder=10)\n",
    "        \n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc40d98-a6c4-4170-89bf-55e40a96b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 goal sequences with >=4 events\n",
      "\n",
      "Action #451\n",
      "Full sequence: ['Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Pass', 'Shot']\n",
      "Model sees: ['Pass', 'Pass', 'Pass', 'Pass', 'Pass']\n",
      "Predicting event #6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel sees: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[id_to_type[t.item()]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mt\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39minput_seq[\u001b[33m'\u001b[39m\u001b[33mtypes\u001b[39m\u001b[33m'\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicting event #\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcutoff+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m fig = \u001b[43mvisualize_mdn_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m plt.savefig(\u001b[33m'\u001b[39m\u001b[33mmdn_heatmap.png\u001b[39m\u001b[33m'\u001b[39m, dpi=\u001b[32m300\u001b[39m, bbox_inches=\u001b[33m'\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     33\u001b[39m plt.show()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mvisualize_mdn_heatmap\u001b[39m\u001b[34m(model, input_seq, device)\u001b[39m\n\u001b[32m     20\u001b[39m     Z += weight * np.exp(-((X - mean[\u001b[32m0\u001b[39m])**\u001b[32m2\u001b[39m + (Y - mean[\u001b[32m1\u001b[39m])**\u001b[32m2\u001b[39m) / (\u001b[32m2\u001b[39m * std**\u001b[32m2\u001b[39m))\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Plot\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m fig, ax = \u001b[43mplt\u001b[49m.subplots(figsize=(\u001b[32m12\u001b[39m, \u001b[32m8\u001b[39m))\n\u001b[32m     24\u001b[39m im = ax.imshow(Z, origin=\u001b[33m'\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m'\u001b[39m, extent=[\u001b[32m0\u001b[39m, \u001b[32m120\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m80\u001b[39m], cmap=\u001b[33m'\u001b[39m\u001b[33mhot\u001b[39m\u001b[33m'\u001b[39m, aspect=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     25\u001b[39m ax.set_xlabel(\u001b[33m'\u001b[39m\u001b[33mX (m)\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# === WYBÓR AKCJI ===\n",
    "goal_sequences = []\n",
    "for i in range(len(val_dataset)):\n",
    "    sample = val_dataset[i]\n",
    "    if (sample['target_types'] == type_vocab['GOAL']).any():\n",
    "        real_len = (sample['input_types'] != type_vocab['<pad>']).sum().item()\n",
    "        if real_len >= 4:\n",
    "            goal_sequences.append((i, sample, real_len))\n",
    "\n",
    "print(f\"Found {len(goal_sequences)} goal sequences with >=4 events\")\n",
    "\n",
    "# ZMIEŃ TUTAJ: który index z goal_sequences\n",
    "action_idx = 17  # 0, 1, 2, ... do zmiany akcji\n",
    "\n",
    "i, sample, real_len = goal_sequences[action_idx]\n",
    "print(f\"\\nAction #{i}\")\n",
    "print(f\"Full sequence: {[id_to_type[t.item()] for t in sample['input_types'][:real_len]]}\")\n",
    "\n",
    "# events_from_end jak poprzednio\n",
    "events_from_end = 6\n",
    "cutoff = real_len - events_from_end\n",
    "input_seq = {\n",
    "    'types': sample['input_types'][:cutoff],\n",
    "    'positions': sample['input_positions'][:cutoff],\n",
    "    'start_mask': sample['input_start_mask'][:cutoff]\n",
    "}\n",
    "\n",
    "print(f\"Model sees: {[id_to_type[t.item()] for t in input_seq['types']]}\")\n",
    "print(f\"Predicting event #{cutoff+1}\")\n",
    "\n",
    "fig = visualize_mdn_heatmap(model, input_seq)\n",
    "plt.savefig('mdn_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
